{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a4ca6f-ab03-4de5-8488-8b67ba0ec4d1",
   "metadata": {},
   "source": [
    "# Live LB on FABRIC \n",
    "\n",
    "This notebook helps sets up a sender and multiple receiver nodes on FABRIC such that they can communicate with the production LB. One of the nodes is designated as a sender and the rest as worker-receivers.\n",
    "\n",
    "See the following diagram:\n",
    "\n",
    "<div>\n",
    "    <img src=\"figs/live-lb.png\" width=500>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5948ab-7637-4fd7-a6c1-0c31e555928e",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "This code should *always* be executed regardless of whether you are starting a new slice or returning to an existing slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d876e2c-21b6-4ac0-9c56-eb04771da7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# EDIT THIS\n",
    "#\n",
    "\n",
    "# GitHub SSH key file (private) registered using the GitHubSSH.ipynb notebook referenced above\n",
    "github_key = '/home/fabric/work/fabric_confi/github_ecdsa'\n",
    "\n",
    "# Note for best management network IPv4 connectivity pick from\n",
    "# 'UCSD', 'SRI', 'FIU' or 'TOKY' - these sites have\n",
    "# IPv4. Other sites use IPv6 management and have trouble\n",
    "# retrieving git-lfs artifacts.\n",
    "\n",
    "# ESnet-FABRIC gateway is at STAR, so the closer we are to it, the lower\n",
    "# the latency and loss.\n",
    "\n",
    "# site_list_override = None\n",
    "\n",
    "# if you want to force a site list instead of using random\n",
    "#site_list_override = ['SRI', 'UCSD', 'CLEM']\n",
    "\n",
    "# (super)core sites - should be low loss\n",
    "site_list_override = ['STAR', 'SALT', 'KANS', 'NEWY', 'WASH', 'LOSA', 'DALL', 'ATLA']\n",
    "\n",
    "# grouped around STAR with optical connections to the backbone - should be low loss\n",
    "#site_list_override = ['STAR', 'INDI', 'NCSA', 'MICH']\n",
    "\n",
    "# high capacity sites (may have losses at high bandwidth)\n",
    "# site_list_override = ['STAR', 'INDI', 'NCSA', 'TACC', 'UCSD', 'PSC']\n",
    "\n",
    "# these we always exclude\n",
    "site_exclude_list = ['EDUKY', 'EDC']\n",
    "\n",
    "# how many workers do we want? (in addition to one sender)\n",
    "number_of_workers = 3\n",
    "\n",
    "# base distro 'ubuntu2[012]' or 'rocky[89]'\n",
    "distro_name = 'ubuntu22'\n",
    "distro_version = distro_name[-2:]\n",
    "\n",
    "# map from distro to image name\n",
    "images = {\n",
    "    'ubuntu20': 'default_ubuntu_20',\n",
    "    'ununtu21': 'default_ubuntu_21',\n",
    "    'ubuntu22': 'default_ubuntu_22',\n",
    "    'rocky8': 'default_rocky_8',\n",
    "    'rocky9': 'default_rocky_9',\n",
    "}\n",
    "\n",
    "# note that the below is distribution specific ('ubuntu' for ubuntu and so on)\n",
    "home_location = {\n",
    "    'ubunt': '/home/ubuntu',\n",
    "    'rocky' : '/home/rocky'\n",
    "}[distro_name[:5]]\n",
    "\n",
    "vm_key_location = f'{home_location}/.ssh/github_ecdsa'\n",
    "\n",
    "# worker dimensions\n",
    "node_attribs = {\n",
    "    'cores': 8,\n",
    "    'disk': 100,\n",
    "    'ram': 24,\n",
    "    'image': images[distro_name]\n",
    "}\n",
    "\n",
    "# slice name\n",
    "slice_name = f'{number_of_workers + 1}-node LB Tester Slice using {distro_name}'\n",
    "\n",
    "# these are subnets we want to be able to route to/from\n",
    "# The list has the form ['192.168.100.0/24', '10.100.1.0/24']\n",
    "external_subnets = []\n",
    "\n",
    "# these are the lists of destination ports we allow to be open on the FABNet interface\n",
    "# for incoming traffic from different subnets. The dictionary has the form\n",
    "# { '192.168.100.0/24': [22, 443] } - the key is the source subnet and the value\n",
    "# is a list of destination ports allowed from that subnet\n",
    "open_ports = {\n",
    "}\n",
    "\n",
    "# url of e2sar deps. Find the appropriate version for the OS at https://github.com/JeffersonLab/E2SAR/releases\n",
    "e2sar_branch = \"main\"\n",
    "static_release_url = 'https://github.com/JeffersonLab/E2SAR/releases/download/' # don't need to change this\n",
    "e2sar_dep_artifcat = 'e2sar-deps_0.1.1_amd64.deb'\n",
    "e2sar_release_ver = 'E2SAR-0.1.1'\n",
    "e2sar_dep_url = static_release_url + e2sar_release_ver + \"-\" + distro_name[:-2] + \"-\" + distro_version + \".04/\" + e2sar_dep_artifcat\n",
    "\n",
    "#\n",
    "# SHOULDN'T NEED TO EDIT BELOW\n",
    "#\n",
    "# Preamble\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from datetime import timedelta\n",
    "\n",
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "\n",
    "from ipaddress import ip_address, IPv4Address, IPv6Address, IPv4Network, IPv6Network\n",
    "import ipaddress\n",
    "\n",
    "fablib = fablib_manager()             \n",
    "fablib.show_config();\n",
    "\n",
    "# gets prepended to site name - this network is per site\n",
    "net_name_prefix = 'fabnetv4ext'\n",
    "\n",
    "# this is the NIC to use\n",
    "nic_model = 'NIC_Basic'\n",
    "\n",
    "def execute_single_node(node, commands):\n",
    "    for command in commands:\n",
    "        print(f'\\tExecuting \"{command}\" on node {node.get_name()}')\n",
    "        #stdout, stderr = node.execute(command, quiet=True, output_file=node.get_name() + '_install.log')\n",
    "        stdout, stderr = node.execute(command)\n",
    "    if not stderr and len(stderr) > 0:\n",
    "        print(f'Error encountered with \"{command}\": {stderr}')\n",
    "        \n",
    "def execute_commands(node, commands):\n",
    "    if isinstance(node, list):\n",
    "        for n in node:\n",
    "            execute_single_node(n, commands)\n",
    "    else:\n",
    "        execute_single_node(node, commands)\n",
    "\n",
    "def execute_single_node_on_thread(node, commands):\n",
    "    # concatenate the commands using ';' and execute\n",
    "    allcommands = ';'.join(commands)\n",
    "    node.execute_thread(allcommands, output_file=node.get_name() + '_thread.log')\n",
    "\n",
    "def execute_commands_on_threads(node, commands):\n",
    "    if isinstance(node, list):\n",
    "        for n in node:\n",
    "            execute_single_node_on_thread(n, commands)\n",
    "    else:\n",
    "        execute_single_node_on_thread(node, commands)\n",
    "\n",
    "def make_node_name(site_name, node_idx):\n",
    "    return '_'.join([f\"Worker{node_idx}\", site_name])\n",
    "\n",
    "def make_net_name(site_name):\n",
    "    return '_'.join([net_name_prefix, site_name])\n",
    "\n",
    "# return slice with one node on one site\n",
    "def starter_slice(site_name):\n",
    "    #node_name = make_node_name(site_name, 1)\n",
    "    node_name = '_'.join([\"Sender\", site_name])\n",
    "    net_name = make_net_name(site_name)\n",
    "\n",
    "    slice = fablib.new_slice(name=slice_name)\n",
    "    node = slice.add_node(name=node_name, site=site_name, **node_attribs)\n",
    "\n",
    "    # postboot configuration is under 'post-boot' directory\n",
    "    node.add_post_boot_upload_directory('post-boot','.')\n",
    "    node.add_post_boot_execute(f'chmod +x post-boot/sender.sh && ./post-boot/sender.sh')\n",
    "    \n",
    "    # attach to network\n",
    "    nic_interface = node.add_component(model=nic_model, name='_'.join([node_name, nic_model, 'nic'])).get_interfaces()[0]\n",
    "    net = slice.add_l3network(name=net_name, interfaces=[nic_interface], type='IPv4Ext')\n",
    "\n",
    "    return slice\n",
    "\n",
    "def add_node_to_slice(site_name, node_idx, inc, slice):\n",
    "\n",
    "    net_name = make_net_name(site_name)\n",
    "\n",
    "    while inc > 0:\n",
    "        node_name = make_node_name(site_name, node_idx)\n",
    "        node_idx += 1\n",
    "        \n",
    "        node = slice.add_node(name=node_name, site=site_name, **node_attribs)\n",
    "    \n",
    "        # postboot configuration is under 'post-boot' directory\n",
    "        node.add_post_boot_upload_directory('post-boot','.')\n",
    "        node.add_post_boot_execute(f'chmod +x post-boot/recver.sh && ./post-boot/recver.sh')\n",
    "    \n",
    "        nic_interface = node.add_component(model=nic_model, name='_'.join([node_name, nic_model, 'nic'])).get_interfaces()[0]\n",
    "        \n",
    "        # attach to a network, create network if needed\n",
    "        net = slice.get_network(name=net_name)\n",
    "        if net is None:\n",
    "            net = slice.add_l3network(name=net_name, type='IPv4Ext')\n",
    "            \n",
    "        net.add_interface(nic_interface)\n",
    "        inc -= 1\n",
    "\n",
    "    return None\n",
    "\n",
    "def check_modify(slice, selected_site_list, nodes_in_slice, expected_to_add):\n",
    "\n",
    "    success = True\n",
    "    idx = 1\n",
    "    while(expected_to_add >= idx):\n",
    "        # find sliver reservation for new node\n",
    "        node_sliver = slice.list_slivers(fields=['name', 'state'], \n",
    "                                         filter_function=lambda x: x['type'] == 'node' and \n",
    "                                             x['name'] == make_node_name(selected_site_list[0], nodes_in_slice + idx) and \n",
    "                                             x['state'] == 'Active')\n",
    "        # if it is none - it failed\n",
    "        if node_sliver is None:\n",
    "            success = False\n",
    "            break\n",
    "        else:\n",
    "            idx += 1\n",
    "\n",
    "    return success\n",
    "\n",
    "# until fablib fixes this\n",
    "def get_management_os_interface(node) -> str or None:\n",
    "        \"\"\"\n",
    "        Gets the name of the management interface used by the node's\n",
    "        operating system. \n",
    "\n",
    "        :return: interface name\n",
    "        :rtype: String\n",
    "        \"\"\"\n",
    "        stdout, stderr = node.execute(\"sudo ip -j route list\", quiet=True)\n",
    "        stdout_json = json.loads(stdout)\n",
    "\n",
    "        for i in stdout_json:\n",
    "            if i[\"dst\"] == \"default\":\n",
    "                return i[\"dev\"]\n",
    "\n",
    "        stdout, stderr = node.execute(\"sudo ip -6 -j route list\", quiet=True)\n",
    "        stdout_json = json.loads(stdout)\n",
    "\n",
    "        for i in stdout_json:\n",
    "            if i[\"dst\"] == \"default\":\n",
    "                return i[\"dev\"]\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c66e2c1-84d0-4228-b552-601b2909c237",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "\n",
    "If you ever forget which images are available, run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38130b75-8dc8-43c8-83cb-497a4768fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available images (this step is optional)\n",
    "available_images = fablib.get_image_names()\n",
    "\n",
    "print(f'Available images are: {available_images}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd114ff-be4f-4be6-8326-e7b088a27e3c",
   "metadata": {},
   "source": [
    "## Prepare to create a new slice (skip if exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec766700-8245-4e4e-bf15-9630f4600456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all slices I have running\n",
    "output_dataframe = fablib.list_slices(output='pandas')\n",
    "if output_dataframe:\n",
    "    print(output_dataframe)\n",
    "else:\n",
    "    print('No active slices under this project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4249e1-42aa-4575-8053-0edf4d95c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify sites in continental US we want to use (NOOP if override is set)\n",
    "lon_west=-124.3993243\n",
    "lon_east=-69.9721573\n",
    "candidate_sites = 7\n",
    "free_nodes_worth = 3 # how many nodes worth are we looking per site\n",
    "\n",
    "# get a list of random sites, avoiding thos on the exclude list\n",
    "# unless there is an override\n",
    "if site_list_override is None:\n",
    "    selected_site_list = fablib.get_random_sites(count=candidate_sites, avoid=site_exclude_list,\n",
    "                                            filter_function=lambda x: x['location'][1] < lon_east\n",
    "                                            and x['location'][1] > lon_west \n",
    "                                            and x['cores_available'] > free_nodes_worth * node_attribs['cores']\n",
    "                                            and x['ram_available'] > free_nodes_worth * node_attribs['ram'] \n",
    "                                            and x['disk_available'] > free_nodes_worth * node_attribs['disk']) \n",
    "else:\n",
    "    selected_site_list = site_list_override\n",
    "\n",
    "if selected_site_list:\n",
    "    print(f'Selected sites are {selected_site_list}')\n",
    "else:\n",
    "    print('Unable to find a sites matching the requirements')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ebd074-4107-483e-b369-79ccd1f99184",
   "metadata": {},
   "source": [
    "## Create slice iteratively (skip if exists)\n",
    "\n",
    "We may or may not get all the nodes we want immediately - we use iteration with slice modify to get to the max/desired number of nodes across the selected sites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9bb82e-6db0-472a-aa3d-66cba06c3d08",
   "metadata": {},
   "source": [
    "### Create Starter Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332540f0-89f5-4038-a28c-d02a454215c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start by establishing a slice with one sender node at some site, we keep track which sites we failed \n",
    "# and don't try those again\n",
    "\n",
    "keep_trying = True\n",
    "succeeded = False\n",
    "\n",
    "site_list_iter = iter(selected_site_list)\n",
    "failed_sites = {}\n",
    "site_name = None\n",
    "\n",
    "while keep_trying:\n",
    "\n",
    "    try:\n",
    "        site_name = next(site_list_iter)\n",
    "        print(f'Trying site {site_name} from {selected_site_list}')\n",
    "        \n",
    "        # define a starter slice\n",
    "        slice = starter_slice(site_name)\n",
    "\n",
    "        print(f'Submitting starter slice \"{slice_name}\" with sender on site {site_name}')\n",
    "        slice_id = slice.submit()\n",
    "\n",
    "        # check the state of this slice\n",
    "        slices = fablib.get_slices(excludes=[], slice_id=slice_id)\n",
    "        if slices[0].get_state() == 'Dead':\n",
    "            print(f'Failed on site {site_name}, proceeding')\n",
    "        else:\n",
    "            print(f'Succeeded on site {site_name} with state {slices[0].get_state()}')\n",
    "            keep_trying = False\n",
    "            succeeded = True\n",
    "    except StopIteration: \n",
    "        print('No more sites to look at, exiting')\n",
    "        keep_trying = False\n",
    "    except Exception as e:\n",
    "        print(f'Unexpected exception {e}, exiting')\n",
    "        keep_trying = False\n",
    "\n",
    "if succeeded:\n",
    "    print(f'Succeeded in creating a slice on {site_name}, will avoid sites {failed_sites}')\n",
    "    selected_site_list = list(filter(lambda x: x not in failed_sites, selected_site_list))\n",
    "    print(f'Proceeding with sites {selected_site_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50070d1-b89f-427e-9a5d-7af7605c8610",
   "metadata": {},
   "source": [
    "### Modify the Slice to add Workers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9270746-f34e-44d6-9c0a-ecc05542a9d0",
   "metadata": {},
   "source": [
    "Now that the base with the sender slice is created we will iteratively add workers on sites one at a time using first-fit policy until we get to the desired number of workers or run out of sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341fd051-3dee-4c0c-8df8-f4222f1068fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_workers = number_of_workers\n",
    "node_idx = 1\n",
    "node_increment = 3\n",
    "nodes_in_slice = 0 # we don't count sender in this case\n",
    "\n",
    "while remaining_workers > 0 and len(selected_site_list) > 0:\n",
    "    slice = fablib.get_slice(name=slice_name)\n",
    "    \n",
    "    try:\n",
    "        site_name = selected_site_list[0]\n",
    "        print(f'There are {remaining_workers} remaining workers to create. Trying site {site_name} from {selected_site_list}')\n",
    "        expected_to_add = node_increment if remaining_workers >= node_increment else remaining_workers\n",
    "        add_node_to_slice(site_name, node_idx, expected_to_add, slice)\n",
    "        \n",
    "        print(f'Submitting slice modification to \"{slice_name}\" to add {expected_to_add} nodes for site {site_name}')\n",
    "        slice_id = slice.modify()\n",
    "        \n",
    "        # check the state of this slice\n",
    "        slice = fablib.get_slice(name=slice_name)\n",
    "\n",
    "        if check_modify(slice, selected_site_list, nodes_in_slice, expected_to_add):\n",
    "            print(f'Succeeded adding {expected_to_add} nodes on site {site_name}.')\n",
    "            # successfully provisioned\n",
    "            node_idx += expected_to_add\n",
    "            remaining_workers -= expected_to_add\n",
    "            nodes_in_slice += expected_to_add\n",
    "        else:\n",
    "            print(f'Failed to provision on site {site_name}.')\n",
    "            # this site is full, moving on\n",
    "            selected_site_list.remove(site_name)            \n",
    "    except Exception as e:\n",
    "        remaining_workers = -1\n",
    "        print(f'Unexpected exception {e}, exiting')\n",
    "        break\n",
    "\n",
    "if remaining_workers == 0:\n",
    "    print('Succeeded in creating all workers')\n",
    "else:\n",
    "    print(f'Unable to create {remaining_workers}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa05d6d-ac6d-47f0-b351-4401b14c05c3",
   "metadata": {},
   "source": [
    "## Get Slice Details (always execute)\n",
    "\n",
    "The following code sets up data structures so all the follow up cells work properly. Execute it regardless of whether you just created the slice or coming back to an existing slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698360b-1118-4fa2-ace0-09bdf3f99a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_net(net_list, name):\n",
    "    for net in net_list:\n",
    "        if net.get_name() == name:\n",
    "            return net\n",
    "    return None\n",
    "\n",
    "# get slice details \n",
    "slice = fablib.get_slice(name=slice_name)\n",
    "\n",
    "a = slice.show()\n",
    "nets = slice.list_networks()\n",
    "nodes = slice.list_nodes()\n",
    "\n",
    "# arrange nodes and network services by site for future convenience\n",
    "net_objects = slice.get_networks()\n",
    "node_objects = slice.get_nodes()\n",
    "available_ip_cnt = 10\n",
    "\n",
    "slivers_by_site = dict()\n",
    "\n",
    "print('Arranging nodes and networks by site and getting available IP addresses')\n",
    "for node in node_objects:\n",
    "    node_site = node.get_site()\n",
    "    if not slivers_by_site.get(node_site):\n",
    "        slivers_by_site[node_site] = dict()\n",
    "        slivers_by_site[node_site]['nodes'] = set()\n",
    "        slivers_by_site[node_site]['net'] = find_net(net_objects, make_net_name(node_site))\n",
    "    slivers_by_site[node_site]['nodes'].add(node)\n",
    "\n",
    "print('Listing public IP addresses per service')\n",
    "for net in net_objects:\n",
    "    print(f'{net.get_name()} has {net.get_public_ips()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f34ea09-c6bb-4bed-b831-35e0f5cf65e8",
   "metadata": {},
   "source": [
    "## Perform Hardening and Network Configuration Opening to Outside World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f49f98c-d88f-4622-b7da-aa4cf797b100",
   "metadata": {},
   "source": [
    "### Set up routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b9b99-defb-4102-a412-fd388763d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate externally routable IP addresses in each site network services\n",
    "# it is NORMAL to see 'IP addresses were updated due to conflicts'\n",
    "for site_name, site_slivers  in slivers_by_site.items():\n",
    "    print(f'Processing {site_name}')\n",
    "    site_net = site_slivers['net']\n",
    "    site_nodes = site_slivers['nodes']\n",
    "    site_slivers['ips'] = site_net.get_available_ips(count=len(site_nodes))\n",
    "    print(f'Requesting available IPs to be publicly routable: {site_slivers[\"ips\"]}')\n",
    "    site_net.make_ip_publicly_routable(ipv4=[str(x) for x in site_slivers['ips']])\n",
    "\n",
    "slice.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc4504-46c7-4807-92cd-28053fc63a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get slice details \n",
    "slice = fablib.get_slice(name=slice_name)\n",
    "\n",
    "# check the results\n",
    "for site_name, site_slivers  in slivers_by_site.items():\n",
    "    print(f'Processing {site_name}')\n",
    "    site_net = site_slivers['net']\n",
    "    site_nodes = site_slivers['nodes']\n",
    "    print(f'Public IPs are: {site_net.get_public_ips()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe7c3d-2d25-47b6-9403-c9b01b4492fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure node interfaces with these IP addresses\n",
    "for site_name, site_slivers in slivers_by_site.items():\n",
    "    print(f'Processing {site_name}')\n",
    "    site_net = site_slivers['net']\n",
    "    site_nodes = site_slivers['nodes']\n",
    "    site_addrs = site_net.get_public_ips()\n",
    "    for node, addr in zip(site_nodes, site_addrs):\n",
    "        print(f'  Adding address {addr} to node {node.get_name()} in subnet {site_net.get_subnet()}')\n",
    "        # make sure the interface is UP (in rare cases comes up in DOWN state)\n",
    "        node_iface = node.get_interface(network_name = site_net.get_name())\n",
    "        execute_single_node(node, [f'sudo ip link set {node_iface.get_os_interface()} up'])\n",
    "        node_iface.ip_addr_add(addr=addr, subnet=site_net.get_subnet())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5a0e5c-f332-42be-9877-ee385eea2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure inter-site routing if you have multiple sites\n",
    "for site_name_from, site_slivers_from in slivers_by_site.items():\n",
    "    for site_name_to, site_slivers_to in slivers_by_site.items():\n",
    "        if site_name_from == site_name_to:\n",
    "            continue\n",
    "        # make sure nodes in site_name_from have a route to site_name_to subnet\n",
    "        subnet = site_slivers_to['net'].get_subnet()\n",
    "        gateway = site_slivers_from['net'].get_gateway()\n",
    "        for node in site_slivers_from['nodes']:\n",
    "            print(f'Setting up route to {subnet} via {gateway} on node {node.get_name()}')\n",
    "            node.ip_route_add(subnet=subnet, gateway=gateway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7808808c-6630-4368-8314-d10779781427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure global routing to indicated subnets \n",
    "for site_name, site_slivers in slivers_by_site.items():\n",
    "    gateway = site_slivers['net'].get_gateway()\n",
    "    for node in site_slivers['nodes']:\n",
    "        print(f'Setting up routes on {node.get_name()}')\n",
    "        for subnet in external_subnets:\n",
    "            print(f'Setting up route to {subnet} via {gateway} on node {node.get_name()}')\n",
    "            execute_single_node(node, [f'sudo ip route add {subnet} via {gateway}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d188265a-7204-493c-acf8-4cdf34f10252",
   "metadata": {},
   "source": [
    "### Setup Firewall (assuming firewalld is used regardless of distro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee04f45-5f8f-4d08-a3eb-177d79c920f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk the nodes, add lo and management interface to 'trusted' zone where everything is allowed\n",
    "# add dataplane interface into 'public' zone where only 'open ports' from specific sources is allowed\n",
    "\n",
    "for site_name, site_slivers in slivers_by_site.items():\n",
    "    site_net = site_slivers['net']\n",
    "    for node in site_slivers['nodes']:\n",
    "        print(f'Setting up firewalld on node {node.get_name()}')\n",
    "        # note we are calling our own function - as of 1.7.0 fablib's node.get_management_os_interface()\n",
    "        # has a bug where it doesn't find management interface on IPv6 sites\n",
    "        mgmt_iface_name = get_management_os_interface(node)\n",
    "        if mgmt_iface_name is None:\n",
    "            print('Unable to determine management interface, skipping')\n",
    "            continue\n",
    "        data_iface = node.get_interface(network_name=site_net.get_name())\n",
    "        data_iface_name = data_iface.get_os_interface()\n",
    "        print(f'  Adding {mgmt_iface_name} and lo to trusted zone and {data_iface_name} to public zone')\n",
    "        commands = [\n",
    "            f'sudo firewall-cmd --permanent --zone=public --add-interface={data_iface_name}',\n",
    "            f'sudo firewall-cmd --permanent --zone=trusted --add-interface=lo',\n",
    "            f'sudo firewall-cmd --permanent --zone=trusted --add-interface={mgmt_iface_name}',\n",
    "            f'for i in $(sudo firewall-cmd --zone=public --list-services); do sudo firewall-cmd --zone=public --permanent --remove-service=$i; done',\n",
    "        ]\n",
    "        for subnet, portlist in open_ports.items():\n",
    "            for port in portlist:\n",
    "                commands.append(f'sudo firewall-cmd --permanent --zone=public --add-rich-rule=\\'rule family=\\\"ipv4\\\" source address=\\\"{subnet}\\\" port protocol=\\\"tcp\\\" port=\\\"{port}\\\" accept\\'')\n",
    "        for subnet in external_subnets:\n",
    "                commands.append(f'sudo firewall-cmd --permanent --zone=public --add-rich-rule=\\'rule family=\\\"ipv4\\\" source address=\\\"{subnet}\\\" protocol value=\\\"udp\\\" accept\\'')\n",
    "        commands.append(f'sudo firewall-cmd --reload')\n",
    "        commands.append(f'sudo firewall-cmd --list-all --zone=public')\n",
    "        execute_single_node(node, commands)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c614a4-b6a2-48bb-9f6e-4ce9b9677ddd",
   "metadata": {},
   "source": [
    "## Tune Buffers and MTUs\n",
    "\n",
    "In order to have good performance we need to\n",
    "- Make the UDP send/receive socket buffer size limit larger (applications are assumed to know how to make their buffers larger up to this limit)\n",
    "- Set MTU to 9k and test with DF=0 ping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c91079-9ce3-4d73-b945-182ffe85dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup UDP socket buffer sizes to 512M\n",
    "commands = [\n",
    "    f\"sudo sysctl net.core.rmem_max=536870912\",\n",
    "    f\"sudo sysctl net.core.wmem_max=536870912\",\n",
    "    f\"sysctl net.core.wmem_max net.core.rmem_max\"\n",
    "]\n",
    "# walk the nodes\n",
    "for site_name, site_slivers in slivers_by_site.items():\n",
    "    for node in site_slivers['nodes']:\n",
    "        execute_single_node(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472d539-252c-4d50-90f8-bb7f9cdd1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set 9k MTU on dataplane interfaces\n",
    "mtu=9000\n",
    "\n",
    "for site_name, site_slivers in slivers_by_site.items():\n",
    "    site_net = site_slivers['net']\n",
    "    for node in site_slivers['nodes']:\n",
    "        data_iface = node.get_interface(network_name=site_net.get_name())\n",
    "        data_iface_name = data_iface.get_os_interface()\n",
    "        execute_single_node(node, [f\"sudo ip link set dev {data_iface_name} mtu {mtu}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ef68c-6da4-4ce7-baee-a8efe7d61d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a no-DF test from every node to the first public address of the first site on the list\n",
    "first_ip = list(slivers_by_site.items())[0][1]['net'].get_public_ips()[0]\n",
    "# you can replace first_ip with the IP of a load balancer, but be careful not to interfere\n",
    "# with a running experiment as this uses ping flood \n",
    "first_ip = \"192.188.29.1\"\n",
    "\n",
    "for site_name, site_slivers in slivers_by_site.items():\n",
    "    for node in site_slivers['nodes']:\n",
    "        print(f'Node {node.get_name()} pinging {first_ip}')\n",
    "        execute_single_node(node, [f\"sudo ping -q -f -s 8972 -c 100 -M do {first_ip}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4551c7f3-c87c-4216-9f66-3e10eba38f90",
   "metadata": {},
   "source": [
    "## Customize Nodes\n",
    "\n",
    "Customize node setup by adding E2SAR installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527b3798-4fb4-447a-a07f-3885936bc55f",
   "metadata": {},
   "source": [
    "### Add E2SAR software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ad8f6b-d909-4076-803e-8adfb9ee9cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install github ssh key and set up build environment variables for interactive logins\n",
    "commands = [\n",
    "    f\"chmod go-rwx {vm_key_location}\",\n",
    "    # Meson won't detect boost by merely setting cmake_prefix_path, instead set BOOST_ROOT env variable \n",
    "    # for gRPC it is enough to set -Dpkg_config_path option to meson\n",
    "    f\"echo 'export BOOST_ROOT=/usr/local/ LD_LIBRARY_PATH=/usr/local/lib' >> ~/.profile\",\n",
    "    f\"echo 'export BOOST_ROOT=/usr/local/ LD_LIBRARY_PATH=/usr/local/lib' >> ~/.bashrc\",\n",
    "]\n",
    "\n",
    "for node in slice.get_nodes():    \n",
    "    # upload the GitHub SSH key onto the VM\n",
    "    result = node.upload_file(github_key, vm_key_location)\n",
    "    execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200a034-e505-41d5-8f5e-6141b6b6cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download boost and grpc dependencies from releases\n",
    "commands = [\n",
    "    f\"wget -q -O boost_grpc.deb {e2sar_dep_url}\",\n",
    "    #f\"sudo apt -yq install ./boost_grpc.deb\",\n",
    "    f\"sudo dpkg -i ./boost_grpc.deb\"\n",
    "]\n",
    " \n",
    "execute_commands(slice.get_nodes(), commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ecc28-3208-43ff-9bd8-49bf74be79af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout E2SAR (including the right branch) using that key, install grpc and boost binary that is stored in the repo\n",
    "commands = [\n",
    "    f\"GIT_SSH_COMMAND='ssh -i {vm_key_location} -o IdentitiesOnly=yes -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no' git clone --recurse-submodules --depth 1 -b {e2sar_branch} git@github.com:JeffersonLab/E2SAR.git\",\n",
    "]\n",
    " \n",
    "execute_commands(slice.get_nodes(), commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f7a098-c295-4a77-8096-f878ffb92015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile and test E2SAR code\n",
    "# note that most live tests only need the simplest URI - ejfats://token@ip:port/\n",
    "# however the e2sar_reas_live_test requires data and sync addresses, and data address must\n",
    "# be real (so we use loopback). Hence the long form of the URI for live tests \n",
    "# (other tests simply ignore the parts of the URI they don't need.)\n",
    "\n",
    "commands = [\n",
    "    f\"cd E2SAR; rm -rf build; PATH=$HOME/.local/bin:/usr/local/bin:$PATH BOOST_ROOT=/usr/local/ LD_LIBRARY_PATH=/usr/local/lib/ meson setup -Dpkg_config_path=/usr/local/lib/pkgconfig/:/usr/lib/lib64/pkgconfig/ --prefix {home_location}/e2sar-install build && sed -i 's/-std=c++11//g' build/build.ninja\",\n",
    "    f\"PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/  meson compile -j 8 -C build\",\n",
    "    f\"PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/  meson test --suite unit  --timeout 0 -C build\",\n",
    "]\n",
    "\n",
    "# NOTE THIS EXECUTES ON THREADS IN PARALLEL, CHECK THE LOG FILES (NodeName_thread_log.log)\n",
    "execute_commands_on_threads(slice.get_nodes(), commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025be1fa-c926-4cf1-aec1-57c37e526f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# if you need to update already cloned repo\n",
    "#\n",
    "# update the code, compile and test\n",
    "# note that most live tests only need the simplest URI - ejfats://token@ip:port/\n",
    "# however the e2sar_reas_live_test requires data and sync addresses, and data address must\n",
    "# be real (so we use loopback). Hence the long form of the URI for live tests \n",
    "# (other tests simply ignore the parts of the URI they don't need.)\n",
    "\n",
    "commands = [\n",
    "    f\"cd E2SAR; GIT_SSH_COMMAND='ssh -i {vm_key_location} -o IdentitiesOnly=yes -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no' git pull origin {e2sar_branch}\",\n",
    "    f\"cd E2SAR; BOOST_ROOT=/usr/local/ PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/ meson setup -Dpkg_config_path=/usr/local/lib/pkgconfig/:/usr/lib/lib64/pkgconfig/ --prefix {home_location}/e2sar-install build --wipe && sed -i 's/-std=c++11//g' build/build.ninja\",\n",
    "    f\"cd E2SAR/build; PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/  meson compile -j 8\",\n",
    "#    f\"cd E2SAR/build; PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/  meson test {e2sar_test_suite} --suite unit --timeout 0\",\n",
    "]\n",
    "  \n",
    "execute_commands(slice.get_nodes(), commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19f887-0a99-488e-8b9e-b72d5247f425",
   "metadata": {},
   "source": [
    "## Run Tests\n",
    "\n",
    "### Run simple single-threaded performance test\n",
    "\n",
    "Start Segmenter on Sender node and one Reassembler on Worker1 and test throughput **without a real load balancer**. Reassembler is told that LB header will be present and it ignores it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3409e1dd-d1fc-4a2e-ae48-46bd76881bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender = list(filter(lambda n: n.get_name()[0:6] == \"Sender\", slice.get_nodes()))[0]\n",
    "recver = list(filter(lambda n: n.get_name()[0:7] == \"Worker1\", slice.get_nodes()))[0]\n",
    "\n",
    "sender_addr = sender.get_interface(network_name=make_net_name(sender.get_site())).get_ip_addr()\n",
    "recver_addr = recver.get_interface(network_name=make_net_name(recver.get_site())).get_ip_addr()\n",
    "print(f\"Sender sending from {sender_addr}, receiver receiving on {recver_addr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a3dcd-c367-4240-9cea-f2bbb45b2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e2sar_perf only the data= part of the query is meaningful. sync= must be present but is ignored\n",
    "# same for gRPC token, address and port (and lb id)\n",
    "e2sarPerfURI = f\"ejfat://useless@10.10.10.10:1234/lb/1?data={recver_addr}&sync=192.168.77.7:1234\"\n",
    "recverDuration = 40\n",
    "mtu = 9000\n",
    "rate = 15 # Gbps\n",
    "length = 1000000 # event length in bytes\n",
    "numEvents = 20000 # number of events to send\n",
    "bufSize = 300 * 1024 * 1024 # 100MB send and receive buffers\n",
    "\n",
    "recv_command = f\"cd E2SAR; PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/ ./build/bin/e2sar_perf -r -u '{e2sarPerfURI}' -d {recverDuration} -b {bufSize} --ip {recver_addr} --port 19522\"\n",
    "send_command = f\"cd E2SAR; PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/ ./build/bin/e2sar_perf -s -u '{e2sarPerfURI}' --mtu {mtu} --rate {rate} --length {length} -n {numEvents} -b {bufSize} --ip {sender_addr}\"\n",
    "\n",
    "# start the receiver for 10 seconds and log its output\n",
    "print(f'Executing command {recv_command} on receiver')\n",
    "recver.execute_thread(recv_command, output_file=f\"{recver.get_name()}.perf.log\")\n",
    "\n",
    "# sleep 2 seconds to let receiver get going\n",
    "time.sleep(2)\n",
    "\n",
    "# start the sender in the foreground\n",
    "print(f'Executing command {send_command} on sender')\n",
    "stdout_send, stderr_send = sender.execute(send_command, output_file=f\"{sender.get_name()}.perf.log\")\n",
    "\n",
    "print(f\"Inspect {recver.get_name()}.perf.log file in your Jupyter container to see the results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c04a61-eebd-4189-9848-1c787995919e",
   "metadata": {},
   "source": [
    "### Reserve the Load Balancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e7e6b-dfd3-44b8-9d92-1df7b9887cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the admin URI\n",
    "ejfat_admin_uri = 'ejfats://replace_me' # cut and paste here\n",
    "\n",
    "lb_path = './E2SAR/build/bin'\n",
    "ld_library_path = \"LD_LIBRARY_PATH=/usr/local/lib\"\n",
    "bin_path = \"PATH=./E2SAR/build/bin:$PATH\"\n",
    "# note we are forcing IPv4 here with -4 option - from FABRIC this is necessary\n",
    "lbadm = f\"{ld_library_path} {bin_path} lbadm -4\"\n",
    "e2sar_perf = f\"{ld_library_path} {bin_path} e2sar_perf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95678748-722e-4e95-8b2c-c2363dc523d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an overview command to see what is reserved\n",
    "# we use sender node but any node can be used for admin commands\n",
    "\n",
    "command = f\"{lbadm} --overview -u {ejfat_admin_uri}\"\n",
    "\n",
    "execute_commands(sender, [command])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96478f5-ca90-4ad7-9544-56330f59e8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve the load balancer\n",
    "lbname = 'e2sar-testlb'\n",
    "duration = '02:00:00' # 2 hours\n",
    "\n",
    "command = f\"{lbadm} --reserve -l {lbname} -a '{sender_addr}' -d {duration} -u '{ejfat_admin_uri}' -e\"\n",
    "execute_commands(sender, [command])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd72bab-8255-486d-a9cd-f753a8a707dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the 'Updated URI after reserve with instance token' from the above result here:\n",
    "instance_uri = 'ejfats://replace_me'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed79af-9715-4fe5-b416-b769bb69503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the status of the reserved LB (as a check)\n",
    "command = f\"{lbadm} --status -u '{instance_uri}'\"\n",
    "execute_commands(sender, [command])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e0c89c-73e0-4d2c-a963-9ba405ba255b",
   "metadata": {},
   "source": [
    "### Run a test with real load balancer and single sender node and single receiver node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e762e-3945-4b74-8a88-91d49b16eaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select sender and receiver\n",
    "sender = list(filter(lambda n: n.get_name()[0:6] == \"Sender\", slice.get_nodes()))[0]\n",
    "recver = list(filter(lambda n: n.get_name()[0:7] == \"Worker1\", slice.get_nodes()))[0]\n",
    "\n",
    "sender_addr = sender.get_interface(network_name=make_net_name(sender.get_site())).get_ip_addr()\n",
    "recver_addr = recver.get_interface(network_name=make_net_name(recver.get_site())).get_ip_addr()\n",
    "print(f\"Sender sending from {sender_addr}, receiver receiving on {recver_addr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a206ef22-bb58-48ed-a1e8-9673e0a7d3b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run sender and receiver through the reserved LB\n",
    "recverDuration = 40\n",
    "mtu = 9000\n",
    "rate = 15 # Gbps\n",
    "length = 1000000 # event length in bytes\n",
    "numEvents = 20000 # number of events to send\n",
    "bufSize = 300 * 1024 * 1024 # 100MB send and receive buffers\n",
    "recvThreads = 4\n",
    "\n",
    "# Given that in FABRIC ejfat-lb.es.net resolves to IP6 first and gRPC C++ library doesn't\n",
    "# offer granular control over which resolved address is used, we use -4 option to tell the\n",
    "# code to use the IPv4 address, but this also disables cert validation.\n",
    "recv_command = f\"{e2sar_perf} -r -u '{instance_uri}' -d {recverDuration} -b {bufSize} --ip {recver_addr} --port 10000 --withcp -4 --threads 4\"\n",
    "send_command = f\"{e2sar_perf} -s -u '{instance_uri}' --mtu {mtu} --rate {rate} --length {length} -n {numEvents} -b {bufSize} --ip {sender_addr} --withcp -4\"\n",
    "\n",
    "# start the receiver for n seconds and log its output\n",
    "print(f'Executing command {recv_command} on receiver')\n",
    "recver.execute_thread(recv_command, output_file=f\"{recver.get_name()}.perf.log\")\n",
    "\n",
    "# sleep 5 seconds to let receiver get going\n",
    "time.sleep(5)\n",
    "\n",
    "# start the sender in the foreground\n",
    "print(f'Executing command {send_command} on sender')\n",
    "stdout_send, stderr_send = sender.execute(send_command, output_file=f\"{sender.get_name()}.perf.log\")\n",
    "\n",
    "print(f\"Inspect {recver.get_name()}.perf.log file to see the results. It should indicate how many events were received and how many lost.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2842c38c-baac-4ad9-8caa-9fb994a92b6d",
   "metadata": {},
   "source": [
    "### Run the test with a single sender node and multiple receiver nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7477f90a-864b-43ef-ab66-16c379fb26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select sender and receivers\n",
    "sender = list(filter(lambda n: n.get_name()[0:6] == \"Sender\", slice.get_nodes()))[0]\n",
    "\n",
    "worker_index = 1\n",
    "recvers = list()\n",
    "recver_addrs = list()\n",
    "while True:\n",
    "    matches = list(filter(lambda n: n.get_name()[0:7] == f\"Worker{worker_index}\", slice.get_nodes()))\n",
    "    if len(matches) == 0:\n",
    "        break\n",
    "    recver = matches[0]\n",
    "    recvers.append(recver)\n",
    "    recver_addr = recver.get_interface(network_name=make_net_name(recver.get_site())).get_ip_addr()\n",
    "    recver_addrs.append(recver_addr)\n",
    "    worker_index += 1\n",
    "    \n",
    "sender_addr = sender.get_interface(network_name=make_net_name(sender.get_site())).get_ip_addr()\n",
    "print(f\"Sender sending from {sender_addr}, receivers receiving on:\")\n",
    "for recver, recver_addr in zip(recvers, recver_addrs):\n",
    "    print(\"\\t\" + recver.get_name() + \": \" + recver_addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8266a685-437f-4e13-8603-1bd550e900c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run sender and receivers through the reserved LB\n",
    "recverDuration = 60\n",
    "mtu = 9000\n",
    "rate = 15 # Gbps\n",
    "length = 1000000 # event length in bytes\n",
    "numEvents = 20000 # number of events to send\n",
    "bufSize = 300 * 1024 * 1024 # 100MB send and receive buffers\n",
    "recvThreads = 4 # on each receiver\n",
    "numSocks = 4 # number send sockets in sender\n",
    "startPort = 10000 # receiver starting port\n",
    "\n",
    "# Given that in FABRIC ejfat-lb.es.net resolves to IP6 first and gRPC C++ library doesn't\n",
    "# offer granular control over which resolved address is used, we use -4 option to tell the\n",
    "# code to use the IPv4 address, but this also disables cert validation.\n",
    "# Sender options of interest:\n",
    "# -z - send 0 event rate in Sync messages\n",
    "# --usec - use usec-precision timestamp as event numbers in Sync and LB messages \n",
    "send_command = f\"{e2sar_perf} -s -u '{instance_uri}' --mtu {mtu} --rate {rate} --length {length} -n {numEvents} -b {bufSize} --ip {sender_addr} --sockets {numSocks} --withcp -4 --usec\"\n",
    "\n",
    "for recver, recver_addr in zip(recvers, recver_addrs):\n",
    "    recv_command = f\"{e2sar_perf} -r -u '{instance_uri}' -d {recverDuration} -b {bufSize} --ip {recver_addr} --port {startPort} --withcp -4 --threads {recvThreads}\"\n",
    "    print(f'Executing command {recv_command} on receiver {recver.get_name()}')\n",
    "    recver.execute_thread(recv_command, output_file=f\"{recver.get_name()}.perf.log\")\n",
    "\n",
    "# sleep 5 seconds to let receivers get going\n",
    "time.sleep(5)\n",
    "\n",
    "# start the sender in the foreground\n",
    "print(f'Executing command {send_command} on sender')\n",
    "stdout_send, stderr_send = sender.execute(send_command, output_file=f\"{sender.get_name()}.perf.log\")\n",
    "\n",
    "print(f\"Inspect WorkerX.perf.log files to see the results. They should indicate how many events were received and how many lost.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41716952-8d5c-4eae-a843-ef5ac0c3ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free the load balancer\n",
    "command = f\"{lbadm} --free -u '{instance_uri}'\"\n",
    "\n",
    "execute_commands(sender, [command])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c8d476-689a-4c4c-b5dc-ed0625410abc",
   "metadata": {},
   "source": [
    "## Manage the slice\n",
    "\n",
    "### Extend by two weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf9fe4f-b067-4d2c-94a5-9839d5a53b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set end host to now plus 14 days\n",
    "end_date = (datetime.now(timezone.utc) + timedelta(days=14)).strftime(\"%Y-%m-%d %H:%M:%S %z\")\n",
    "\n",
    "try:\n",
    "    slice = fablib.get_slice(name=slice_name)\n",
    "\n",
    "    slice.renew(end_date)\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb476a-2b17-4064-9a0e-a7a98d865804",
   "metadata": {},
   "source": [
    "### Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3546bf-a013-4eaa-bab1-fb52f7d36c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(slice_name)\n",
    "slice.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737f112-95d3-4a78-9b15-f16ae98e7f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
