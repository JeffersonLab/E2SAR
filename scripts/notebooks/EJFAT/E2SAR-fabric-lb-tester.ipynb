{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a4ca6f-ab03-4de5-8488-8b67ba0ec4d1",
   "metadata": {},
   "source": [
    "# Testing LB on FABRIC U280\n",
    "\n",
    "This notebook helps sets up a sender and multiple receiver nodes on FABRIC such that they can communicate with a LB provisioned in FABRIC. Unlike the 'FABRIC-live-lb-tester' notebook, this one does NOT use FABNetv4Ext service - only FABNetv4, consequently the security measures are more limited, since none of this is exposed to the internet. One of the nodes is designated as a sender and the rest as worker-receivers.\n",
    "\n",
    "See the following diagram:\n",
    "\n",
    "<div>\n",
    "    <img src=\"figs/live-lb.png\" width=500>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5948ab-7637-4fd7-a6c1-0c31e555928e",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "This code should *always* be executed regardless of whether you are starting a new slice or returning to an existing slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d876e2c-21b6-4ac0-9c56-eb04771da7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# EDIT THIS\n",
    "#\n",
    "\n",
    "# GitHub SSH key file (private) registered using the GitHubSSH.ipynb notebook referenced above\n",
    "github_key = '/home/fabric/work/fabric_confi/github_ecdsa'\n",
    "\n",
    "# Note for best management network IPv4 connectivity pick from\n",
    "# 'UCSD', 'SRI', 'FIU' or 'TOKY' - these sites have\n",
    "# IPv4. Other sites use IPv6 management and have trouble\n",
    "# retrieving git-lfs artifacts.\n",
    "\n",
    "# site_list_override = None\n",
    "\n",
    "# if you want to force a site list instead of using random\n",
    "#site_list_override = ['SRI', 'UCSD', 'CLEM']\n",
    "\n",
    "# (super)core sites - should be low loss\n",
    "site_list_override = ['SALT', 'KANS', 'NEWY', 'WASH', 'LOSA', 'DALL', 'ATLA']\n",
    "\n",
    "# high capacity sites (may have losses at high bandwidth)\n",
    "# site_list_override = ['STAR', 'INDI', 'NCSA', 'TACC', 'UCSD', 'PSC']\n",
    "\n",
    "# these we always exclude\n",
    "site_exclude_list = ['EDUKY', 'EDC']\n",
    "\n",
    "# how many workers do we want? (in addition to one sender)\n",
    "number_of_workers = 3\n",
    "\n",
    "# base distro 'ubuntu2[012]' or 'rocky[89]'\n",
    "distro_name = 'ubuntu22'\n",
    "distro_version = distro_name[-2:]\n",
    "\n",
    "# map from distro to image name\n",
    "images = {\n",
    "    'ubuntu20': 'default_ubuntu_20',\n",
    "    'ununtu21': 'default_ubuntu_21',\n",
    "    'ubuntu22': 'default_ubuntu_22',\n",
    "    'rocky8': 'default_rocky_8',\n",
    "    'rocky9': 'default_rocky_9',\n",
    "}\n",
    "\n",
    "# note that the below is distribution specific ('ubuntu' for ubuntu and so on)\n",
    "home_location = {\n",
    "    'ubunt': '/home/ubuntu',\n",
    "    'rocky' : '/home/rocky'\n",
    "}[distro_name[:5]]\n",
    "\n",
    "vm_key_location = f'{home_location}/.ssh/github_ecdsa'\n",
    "\n",
    "# worker dimensions\n",
    "node_attribs = {\n",
    "    'cores': 8,\n",
    "    'disk': 100,\n",
    "    'ram': 24,\n",
    "    'image': images[distro_name]\n",
    "}\n",
    "\n",
    "# slice name\n",
    "slice_name = f'{number_of_workers + 1}-node U280 LB Tester Slice using {distro_name} 1'\n",
    "\n",
    "# url of e2sar deps. Find the appropriate version for the OS at https://github.com/JeffersonLab/E2SAR/releases\n",
    "e2sar_branch = \"main\"\n",
    "static_release_url = 'https://github.com/JeffersonLab/E2SAR/releases/download/' # don't need to change this\n",
    "e2sar_dep_artifcat = 'e2sar-deps_0.1.4_amd64.deb'\n",
    "e2sar_release_ver = 'E2SAR-main-0.1.4'\n",
    "e2sar_dep_url = static_release_url + e2sar_release_ver + \"-\" + distro_name[:-2] + \"-\" + distro_version + \".04/\" + e2sar_dep_artifcat\n",
    "\n",
    "# this is the IPv4 address and Control Plane listening port of the LB node created by the other notebook\n",
    "lb_node_ip = \"10.138.47.254\"\n",
    "lb_cp_port = 18008\n",
    "# the admin token is also generated by the U280 LB notebook\n",
    "lb_admin_token = \"0DTIKKNEYMMOUP283AP8UM4ABI45PNJ3\"\n",
    "\n",
    "ejfat_admin_uri = f\"ejfats://{lb_admin_token}@{lb_node_ip}:{lb_cp_port}/\"\n",
    "\n",
    "#\n",
    "# SHOULDN'T NEED TO EDIT BELOW\n",
    "#\n",
    "# Preamble\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from datetime import timedelta\n",
    "\n",
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "\n",
    "from ipaddress import ip_address, IPv4Address, IPv6Address, IPv4Network, IPv6Network\n",
    "import ipaddress\n",
    "\n",
    "fablib = fablib_manager()             \n",
    "fablib.show_config();\n",
    "\n",
    "# gets prepended to site name - this network is per site\n",
    "net_name_prefix = 'fabnetv4'\n",
    "\n",
    "# this is the NIC to use\n",
    "nic_model = 'NIC_Basic'\n",
    "\n",
    "def execute_single_node(node, commands):\n",
    "    for command in commands:\n",
    "        print(f'\\tExecuting \"{command}\" on node {node.get_name()}')\n",
    "        #stdout, stderr = node.execute(command, quiet=True, output_file=node.get_name() + '_install.log')\n",
    "        stdout, stderr = node.execute(command)\n",
    "    if not stderr and len(stderr) > 0:\n",
    "        print(f'Error encountered with \"{command}\": {stderr}')\n",
    "        \n",
    "def execute_commands(node, commands):\n",
    "    if isinstance(node, list):\n",
    "        for n in node:\n",
    "            execute_single_node(n, commands)\n",
    "    else:\n",
    "        execute_single_node(node, commands)\n",
    "\n",
    "def execute_single_node_on_thread(node, commands):\n",
    "    # concatenate the commands using ';' and execute\n",
    "    allcommands = ';'.join(commands)\n",
    "    node.execute_thread(allcommands, output_file=node.get_name() + '_thread.log')\n",
    "\n",
    "def execute_commands_on_threads(node, commands):\n",
    "    if isinstance(node, list):\n",
    "        for n in node:\n",
    "            execute_single_node_on_thread(n, commands)\n",
    "    else:\n",
    "        execute_single_node_on_thread(node, commands)\n",
    "\n",
    "def make_node_name(site_name, node_idx):\n",
    "    return '_'.join([f\"Worker{node_idx}\", site_name])\n",
    "\n",
    "def make_net_name(site_name):\n",
    "    return '_'.join([net_name_prefix, site_name])\n",
    "\n",
    "# return slice with one node on one site\n",
    "def starter_slice(site_name):\n",
    "    #node_name = make_node_name(site_name, 1)\n",
    "    node_name = '_'.join([\"Sender\", site_name])\n",
    "    net_name = make_net_name(site_name)\n",
    "\n",
    "    slice = fablib.new_slice(name=slice_name)\n",
    "    node = slice.add_node(name=node_name, site=site_name, **node_attribs)\n",
    "\n",
    "    # postboot configuration is under 'post-boot' directory\n",
    "    node.add_post_boot_upload_directory('post-boot','.')\n",
    "    node.add_post_boot_execute(f'chmod +x post-boot/sender.sh && ./post-boot/sender.sh')\n",
    "    \n",
    "    # attach to network\n",
    "    nic_interface = node.add_component(model=nic_model, name='_'.join([node_name, nic_model, 'nic'])).get_interfaces()[0]\n",
    "    net = slice.add_l3network(name=net_name, interfaces=[nic_interface], type='IPv4')\n",
    "\n",
    "    return slice\n",
    "\n",
    "def add_node_to_slice(site_name, node_idx, inc, slice):\n",
    "\n",
    "    net_name = make_net_name(site_name)\n",
    "\n",
    "    while inc > 0:\n",
    "        node_name = make_node_name(site_name, node_idx)\n",
    "        node_idx += 1\n",
    "        \n",
    "        node = slice.add_node(name=node_name, site=site_name, **node_attribs)\n",
    "    \n",
    "        # postboot configuration is under 'post-boot' directory\n",
    "        node.add_post_boot_upload_directory('post-boot','.')\n",
    "        node.add_post_boot_execute(f'chmod +x post-boot/recver.sh && ./post-boot/recver.sh')\n",
    "    \n",
    "        nic_interface = node.add_component(model=nic_model, name='_'.join([node_name, nic_model, 'nic'])).get_interfaces()[0]\n",
    "        \n",
    "        # attach to a network, create network if needed\n",
    "        net = slice.get_network(name=net_name)\n",
    "        if net is None:\n",
    "            net = slice.add_l3network(name=net_name, type='IPv4')\n",
    "            \n",
    "        net.add_interface(nic_interface)\n",
    "        inc -= 1\n",
    "\n",
    "    return None\n",
    "\n",
    "def check_modify(slice, selected_site_list, nodes_in_slice, expected_to_add):\n",
    "\n",
    "    success = True\n",
    "    idx = 1\n",
    "    while(expected_to_add >= idx):\n",
    "        # find sliver reservation for new node\n",
    "        node_sliver = slice.list_slivers(fields=['name', 'state'], \n",
    "                                         filter_function=lambda x: x['type'] == 'node' and \n",
    "                                             x['name'] == make_node_name(selected_site_list[0], nodes_in_slice + idx) and \n",
    "                                             x['state'] == 'Active')\n",
    "        # if it is none - it failed\n",
    "        if node_sliver is None:\n",
    "            success = False\n",
    "            break\n",
    "        else:\n",
    "            idx += 1\n",
    "\n",
    "    return success\n",
    "\n",
    "# until fablib fixes this\n",
    "def get_management_os_interface(node) -> str or None:\n",
    "        \"\"\"\n",
    "        Gets the name of the management interface used by the node's\n",
    "        operating system. \n",
    "\n",
    "        :return: interface name\n",
    "        :rtype: String\n",
    "        \"\"\"\n",
    "        stdout, stderr = node.execute(\"sudo ip -j route list\", quiet=True)\n",
    "        stdout_json = json.loads(stdout)\n",
    "\n",
    "        for i in stdout_json:\n",
    "            if i[\"dst\"] == \"default\":\n",
    "                return i[\"dev\"]\n",
    "\n",
    "        stdout, stderr = node.execute(\"sudo ip -6 -j route list\", quiet=True)\n",
    "        stdout_json = json.loads(stdout)\n",
    "\n",
    "        for i in stdout_json:\n",
    "            if i[\"dst\"] == \"default\":\n",
    "                return i[\"dev\"]\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c66e2c1-84d0-4228-b552-601b2909c237",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "\n",
    "If you ever forget which images are available, run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38130b75-8dc8-43c8-83cb-497a4768fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available images (this step is optional)\n",
    "available_images = fablib.get_image_names()\n",
    "\n",
    "print(f'Available images are: {available_images}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd114ff-be4f-4be6-8326-e7b088a27e3c",
   "metadata": {},
   "source": [
    "## Prepare to create a new slice (skip if exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec766700-8245-4e4e-bf15-9630f4600456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all slices I have running\n",
    "output_dataframe = fablib.list_slices(output='pandas')\n",
    "if output_dataframe:\n",
    "    print(output_dataframe)\n",
    "else:\n",
    "    print('No active slices under this project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4249e1-42aa-4575-8053-0edf4d95c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify sites in continental US we want to use (NOOP if override is set)\n",
    "lon_west=-124.3993243\n",
    "lon_east=-69.9721573\n",
    "candidate_sites = 7\n",
    "free_nodes_worth = 3 # how many nodes worth are we looking per site\n",
    "\n",
    "# get a list of random sites, avoiding thos on the exclude list\n",
    "# unless there is an override\n",
    "if site_list_override is None:\n",
    "    selected_site_list = fablib.get_random_sites(count=candidate_sites, avoid=site_exclude_list,\n",
    "                                            filter_function=lambda x: x['location'][1] < lon_east\n",
    "                                            and x['location'][1] > lon_west \n",
    "                                            and x['cores_available'] > free_nodes_worth * node_attribs['cores']\n",
    "                                            and x['ram_available'] > free_nodes_worth * node_attribs['ram'] \n",
    "                                            and x['disk_available'] > free_nodes_worth * node_attribs['disk']) \n",
    "else:\n",
    "    selected_site_list = site_list_override\n",
    "\n",
    "if selected_site_list:\n",
    "    print(f'Selected sites are {selected_site_list}')\n",
    "else:\n",
    "    print('Unable to find a sites matching the requirements')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ebd074-4107-483e-b369-79ccd1f99184",
   "metadata": {},
   "source": [
    "## Create slice iteratively (skip if exists)\n",
    "\n",
    "We may or may not get all the nodes we want immediately - we use iteration with slice modify to get to the max/desired number of nodes across the selected sites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9bb82e-6db0-472a-aa3d-66cba06c3d08",
   "metadata": {},
   "source": [
    "### Create Starter Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332540f0-89f5-4038-a28c-d02a454215c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start by establishing a slice with one sender node at some site, we keep track which sites we failed \n",
    "# and don't try those again\n",
    "\n",
    "keep_trying = True\n",
    "succeeded = False\n",
    "\n",
    "site_list_iter = iter(selected_site_list)\n",
    "failed_sites = {}\n",
    "site_name = None\n",
    "\n",
    "while keep_trying:\n",
    "\n",
    "    try:\n",
    "        site_name = next(site_list_iter)\n",
    "        print(f'Trying site {site_name} from {selected_site_list}')\n",
    "        \n",
    "        # define a starter slice\n",
    "        slice = starter_slice(site_name)\n",
    "\n",
    "        print(f'Submitting starter slice \"{slice_name}\" with sender on site {site_name}')\n",
    "        slice_id = slice.submit()\n",
    "\n",
    "        # check the state of this slice\n",
    "        slices = fablib.get_slices(excludes=[], slice_id=slice_id)\n",
    "        if slices[0].get_state() == 'Dead':\n",
    "            print(f'Failed on site {site_name}, proceeding')\n",
    "        else:\n",
    "            print(f'Succeeded on site {site_name} with state {slices[0].get_state()}')\n",
    "            keep_trying = False\n",
    "            succeeded = True\n",
    "    except StopIteration: \n",
    "        print('No more sites to look at, exiting')\n",
    "        keep_trying = False\n",
    "    except Exception as e:\n",
    "        print(f'Unexpected exception {e}, exiting')\n",
    "        keep_trying = False\n",
    "\n",
    "if succeeded:\n",
    "    print(f'Succeeded in creating a slice on {site_name}, will avoid sites {failed_sites}')\n",
    "    selected_site_list = list(filter(lambda x: x not in failed_sites, selected_site_list))\n",
    "    print(f'Proceeding with sites {selected_site_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50070d1-b89f-427e-9a5d-7af7605c8610",
   "metadata": {},
   "source": [
    "### Modify the Slice to add Workers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9270746-f34e-44d6-9c0a-ecc05542a9d0",
   "metadata": {},
   "source": [
    "Now that the base with the sender slice is created we will iteratively add workers on sites one at a time using first-fit policy until we get to the desired number of workers or run out of sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341fd051-3dee-4c0c-8df8-f4222f1068fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_workers = number_of_workers\n",
    "node_idx = 1\n",
    "node_increment = 3\n",
    "nodes_in_slice = 0 # we don't count sender in this case\n",
    "\n",
    "while remaining_workers > 0 and len(selected_site_list) > 0:\n",
    "    slice = fablib.get_slice(name=slice_name)\n",
    "    \n",
    "    try:\n",
    "        site_name = selected_site_list[0]\n",
    "        print(f'There are {remaining_workers} remaining workers to create. Trying site {site_name} from {selected_site_list}')\n",
    "        expected_to_add = node_increment if remaining_workers >= node_increment else remaining_workers\n",
    "        add_node_to_slice(site_name, node_idx, expected_to_add, slice)\n",
    "        \n",
    "        print(f'Submitting slice modification to \"{slice_name}\" to add {expected_to_add} nodes for site {site_name}')\n",
    "        slice_id = slice.modify()\n",
    "        \n",
    "        # check the state of this slice\n",
    "        slice = fablib.get_slice(name=slice_name)\n",
    "\n",
    "        if check_modify(slice, selected_site_list, nodes_in_slice, expected_to_add):\n",
    "            print(f'Succeeded adding {expected_to_add} nodes on site {site_name}.')\n",
    "            # successfully provisioned\n",
    "            node_idx += expected_to_add\n",
    "            remaining_workers -= expected_to_add\n",
    "            nodes_in_slice += expected_to_add\n",
    "        else:\n",
    "            print(f'Failed to provision on site {site_name}.')\n",
    "            # this site is full, moving on\n",
    "            selected_site_list.remove(site_name)            \n",
    "    except Exception as e:\n",
    "        remaining_workers = -1\n",
    "        print(f'Unexpected exception {e}, exiting')\n",
    "        break\n",
    "\n",
    "if remaining_workers == 0:\n",
    "    print('Succeeded in creating all workers')\n",
    "else:\n",
    "    print(f'Unable to create {remaining_workers}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa05d6d-ac6d-47f0-b351-4401b14c05c3",
   "metadata": {},
   "source": [
    "## Get Slice Details (always execute)\n",
    "\n",
    "The following code sets up data structures so all the follow up cells work properly. Execute it regardless of whether you just created the slice or coming back to an existing slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698360b-1118-4fa2-ace0-09bdf3f99a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_net(net_list, name):\n",
    "    return next(filter(lambda x: x.get_name() == name, net_list), None)\n",
    "\n",
    "# this is the full /10 routable FABRIC IPv4\n",
    "full_subnet = ipaddress.IPv4Network('10.128.0.0/10')\n",
    "\n",
    "# get slice details \n",
    "slice = fablib.get_slice(name=slice_name)\n",
    "\n",
    "a = slice.show()\n",
    "nets = slice.list_networks()\n",
    "nodes = slice.list_nodes()\n",
    "\n",
    "# arrange nodes and network services by site for future convenience\n",
    "net_objects = slice.get_networks()\n",
    "node_objects = slice.get_nodes()\n",
    "\n",
    "slivers_by_site = dict()\n",
    "\n",
    "print('Arranging nodes and networks by site and getting available IP addresses')\n",
    "for node in node_objects:\n",
    "    node_site = node.get_site()\n",
    "    if not slivers_by_site.get(node_site):\n",
    "        slivers_by_site[node_site] = dict()\n",
    "        slivers_by_site[node_site]['nodes'] = set()\n",
    "        slivers_by_site[node_site]['net'] = find_net(net_objects, make_net_name(node_site))\n",
    "    slivers_by_site[node_site]['nodes'].add(node)\n",
    "\n",
    "print('Listing IPv4 addresses per service (per site)')\n",
    "for net in net_objects:\n",
    "    print(f'{net.get_name()} has {net.get_subnet()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f34ea09-c6bb-4bed-b831-35e0f5cf65e8",
   "metadata": {},
   "source": [
    "## Perform network configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f49f98c-d88f-4622-b7da-aa4cf797b100",
   "metadata": {},
   "source": [
    "### Set up routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b9b99-defb-4102-a412-fd388763d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_ips(ip_list, gateway, qty=1):\n",
    "    # make sure the returned IP isn't the gateway\n",
    "    ips = []\n",
    "    while qty > 0:\n",
    "        ip = ip_list.pop()\n",
    "        while ip == gateway:\n",
    "            ip = ip_list.pop()\n",
    "        ips.append(ip)\n",
    "        qty -= 1\n",
    "\n",
    "    return ips\n",
    "\n",
    "# allocate IP addresses in each site network services\n",
    "print('Allocating IP addresses in sites where slice is present')\n",
    "for site_name, site_slivers  in slivers_by_site.items():\n",
    "    print(f'Processing {site_name}')\n",
    "    site_net = site_slivers['net']\n",
    "    site_nodes = site_slivers['nodes']\n",
    "    # this properly lists needed available IPs for this subnet\n",
    "    site_slivers['ips'] = list(site_net.get_subnet().hosts())[:len(site_nodes)]\n",
    "    site_slivers['ips'] = get_valid_ips(list(site_net.get_subnet().hosts()), site_net.get_gateway(), len(site_nodes))\n",
    "    print(f'Using the following IPs: {site_slivers[\"ips\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe7c3d-2d25-47b6-9403-c9b01b4492fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure node interfaces with these IP addresses\n",
    "print('Configuring interfaces on nodes')\n",
    "for site_name, site_slivers in slivers_by_site.items():\n",
    "    print(f'Processing {site_name}')\n",
    "    site_net = site_slivers['net']\n",
    "    site_nodes = site_slivers['nodes']\n",
    "    site_addrs = site_slivers['ips']\n",
    "    for node, addr in zip(site_nodes, site_addrs):\n",
    "        print(f'  Adding address {addr} to node {node.get_name()} in subnet {site_net.get_subnet()}')\n",
    "        # make sure the interface is UP (in rare cases comes up in DOWN state)\n",
    "        node_iface = node.get_interface(network_name=site_net.get_name())\n",
    "        execute_single_node(node, [f'sudo ip link set {node_iface.get_os_interface()} up'])\n",
    "        node_iface.ip_addr_add(addr=addr, subnet=site_net.get_subnet())\n",
    "        node.ip_route_add(subnet=full_subnet, gateway=site_net.get_gateway())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb15db-70ec-4994-93e5-9b2da90ae97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to setup the firewall to allow UDP traffic to pass between the nodes\n",
    "# we do this by moving all interfaces (loopback, management and data) to the 'trusted' zone\n",
    "# since we are in FABNetv4 we can keep things simple\n",
    "\n",
    "for site_name, site_slivers in slivers_by_site.items():\n",
    "    print(f'Processing {site_name}')\n",
    "    site_net = site_slivers['net']\n",
    "    for node in site_slivers['nodes']:\n",
    "        mgmt_iface_name = get_management_os_interface(node)\n",
    "        data_iface = node.get_interface(network_name=site_net.get_name())\n",
    "        data_iface_name = data_iface.get_os_interface()\n",
    "        commands = [\n",
    "            f'sudo firewall-cmd --permanent --zone=trusted --add-interface={data_iface_name}',\n",
    "            f'sudo firewall-cmd --permanent --zone=trusted --add-interface=lo',\n",
    "            f'sudo firewall-cmd --permanent --zone=trusted --add-interface={mgmt_iface_name}',\n",
    "            f'for i in $(sudo firewall-cmd --zone=public --list-services); do sudo firewall-cmd --zone=public --permanent --remove-service=$i; done',\n",
    "        ]\n",
    "        commands.append(f'sudo firewall-cmd --reload')\n",
    "        commands.append(f'sudo firewall-cmd --list-all --zone=trusted')\n",
    "        execute_commands([node], commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c614a4-b6a2-48bb-9f6e-4ce9b9677ddd",
   "metadata": {},
   "source": [
    "## Tune Buffers and MTUs\n",
    "\n",
    "In order to have good performance we need to\n",
    "- Make the UDP send/receive socket buffer size limit larger (applications are assumed to know how to make their buffers larger up to this limit)\n",
    "- Set MTU to 9k and test with DF=0 ping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c91079-9ce3-4d73-b945-182ffe85dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup UDP socket buffer sizes to 512M\n",
    "commands = [\n",
    "    f\"sudo sysctl net.core.rmem_max=536870912\",\n",
    "    f\"sudo sysctl net.core.wmem_max=536870912\",\n",
    "    f\"sysctl net.core.wmem_max net.core.rmem_max\"\n",
    "]\n",
    "# walk the nodes\n",
    "for site_name, site_slivers in slivers_by_site.items():\n",
    "    for node in site_slivers['nodes']:\n",
    "        execute_single_node(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472d539-252c-4d50-90f8-bb7f9cdd1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set 9k MTU on dataplane interfaces\n",
    "mtu=9000\n",
    "\n",
    "for site_name, site_slivers in slivers_by_site.items():\n",
    "    site_net = site_slivers['net']\n",
    "    for node in site_slivers['nodes']:\n",
    "        data_iface = node.get_interface(network_name=site_net.get_name())\n",
    "        data_iface_name = data_iface.get_os_interface()\n",
    "        execute_single_node(node, [f\"sudo ip link set dev {data_iface_name} mtu {mtu}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ef68c-6da4-4ce7-baee-a8efe7d61d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a test from every node to the LB node\n",
    "for site_name, site_slivers in slivers_by_site.items():\n",
    "    for node in site_slivers['nodes']:\n",
    "        print(f'Node {node.get_name()} pinging {lb_node_ip}')\n",
    "        #execute_single_node(node, [f\"sudo ping -q -f -s 8972 -c 100 -M do {lb_node_ip}\"])\n",
    "        execute_single_node(node, [f\"sudo ping -q -f -c 100 {lb_node_ip}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4551c7f3-c87c-4216-9f66-3e10eba38f90",
   "metadata": {},
   "source": [
    "## Customize Nodes\n",
    "\n",
    "Customize node setup by adding E2SAR installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527b3798-4fb4-447a-a07f-3885936bc55f",
   "metadata": {},
   "source": [
    "### Add E2SAR software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ad8f6b-d909-4076-803e-8adfb9ee9cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install github ssh key and set up build environment variables for interactive logins\n",
    "commands = [\n",
    "    f\"chmod go-rwx {vm_key_location}\",\n",
    "    # Meson won't detect boost by merely setting cmake_prefix_path, instead set BOOST_ROOT env variable \n",
    "    # for gRPC it is enough to set -Dpkg_config_path option to meson\n",
    "    f\"echo 'export BOOST_ROOT=/usr/local/ LD_LIBRARY_PATH=/usr/local/lib' >> ~/.profile\",\n",
    "    f\"echo 'export BOOST_ROOT=/usr/local/ LD_LIBRARY_PATH=/usr/local/lib' >> ~/.bashrc\",\n",
    "]\n",
    "\n",
    "for node in slice.get_nodes():    \n",
    "    # upload the GitHub SSH key onto the VM\n",
    "    result = node.upload_file(github_key, vm_key_location)\n",
    "    execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200a034-e505-41d5-8f5e-6141b6b6cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download boost and grpc dependencies from releases\n",
    "commands = [\n",
    "    f\"wget -q -O boost_grpc.deb {e2sar_dep_url}\",\n",
    "    #f\"sudo apt -yq install ./boost_grpc.deb\",\n",
    "    f\"sudo dpkg -i ./boost_grpc.deb\"\n",
    "]\n",
    " \n",
    "execute_commands_on_threads(slice.get_nodes(), commands)\n",
    "print(\"Note this is executed in parallel on threads, check the log files for completion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ecc28-3208-43ff-9bd8-49bf74be79af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout E2SAR (including the righte branch) using that key, install grpc and boost binary that is stored in the repo\n",
    "branch_override=None\n",
    "if branch_override is not None:\n",
    "    branch = branch_override\n",
    "else:\n",
    "    branch = e2sar_branch\n",
    "    \n",
    "commands = [\n",
    "    f\"rm -rf E2SAR\",\n",
    "    f\"GIT_SSH_COMMAND='ssh -i {vm_key_location} -o IdentitiesOnly=yes -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no' git clone --recurse-submodules --depth 1 -b {branch} git@github.com:JeffersonLab/E2SAR.git\",\n",
    "]\n",
    " \n",
    "execute_commands(slice.get_nodes(), commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f7a098-c295-4a77-8096-f878ffb92015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile and test E2SAR code\n",
    "# note that most live tests only need the simplest URI - ejfats://token@ip:port/\n",
    "# however the e2sar_reas_live_test requires data and sync addresses, and data address must\n",
    "# be real (so we use loopback). Hence the long form of the URI for live tests \n",
    "# (other tests simply ignore the parts of the URI they don't need.)\n",
    "\n",
    "commands = [\n",
    "    f\"cd E2SAR; rm -rf build; PATH=$HOME/.local/bin:/usr/local/bin:$PATH BOOST_ROOT=/usr/local/ LD_LIBRARY_PATH=/usr/local/lib/ meson setup -Dpkg_config_path=/usr/local/lib/pkgconfig/:/usr/lib/lib64/pkgconfig/ --prefix {home_location}/e2sar-install build && sed -i 's/-std=c++11//g' build/build.ninja\",\n",
    "    f\"PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/  meson compile -j 8 -C build\",\n",
    "    f\"PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/  meson test --suite unit  --timeout 0 -C build\",\n",
    "]\n",
    "\n",
    "# NOTE THIS EXECUTES ON THREADS IN PARALLEL, CHECK THE LOG FILES (NodeName_thread_log.log)\n",
    "execute_commands_on_threads(slice.get_nodes(), commands)\n",
    "print(\"Note this is executed on threads, check the log files for completion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025be1fa-c926-4cf1-aec1-57c37e526f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# if you need to update already cloned repo\n",
    "#\n",
    "# update the code, compile and test\n",
    "# note that most live tests only need the simplest URI - ejfats://token@ip:port/\n",
    "# however the e2sar_reas_live_test requires data and sync addresses, and data address must\n",
    "# be real (so we use loopback). Hence the long form of the URI for live tests \n",
    "# (other tests simply ignore the parts of the URI they don't need.)\n",
    "\n",
    "commands = [\n",
    "    f\"cd E2SAR; GIT_SSH_COMMAND='ssh -i {vm_key_location} -o IdentitiesOnly=yes -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no' git pull origin {e2sar_branch}\",\n",
    "    f\"BOOST_ROOT=/usr/local/ PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/ meson setup -Dpkg_config_path=/usr/local/lib/pkgconfig/:/usr/lib/lib64/pkgconfig/ --prefix {home_location}/e2sar-install build --wipe && sed -i 's/-std=c++11//g' build/build.ninja\",\n",
    "    f\"PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/  meson compile -j 8 -C build\",\n",
    "#    f\"cd E2SAR/build; PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/  meson test {e2sar_test_suite} --suite unit --timeout 0\",\n",
    "]\n",
    "  \n",
    "execute_commands_on_threads(slice.get_nodes(), commands)\n",
    "print(\"Note this is executed on threads, check the log files for completion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19f887-0a99-488e-8b9e-b72d5247f425",
   "metadata": {},
   "source": [
    "## Run Tests\n",
    "\n",
    "### Run simple single-threaded performance test\n",
    "\n",
    "Start Segmenter on Sender node and one Reassembler on Worker1 and test throughput **without a real load balancer**. Reassembler is told that LB header will be present and it ignores it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3409e1dd-d1fc-4a2e-ae48-46bd76881bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender = list(filter(lambda n: n.get_name()[0:6] == \"Sender\", slice.get_nodes()))[0]\n",
    "recver = list(filter(lambda n: n.get_name()[0:7] == \"Worker1\", slice.get_nodes()))[0]\n",
    "\n",
    "sender_addr = sender.get_interface(network_name=make_net_name(sender.get_site())).get_ip_addr()\n",
    "recver_addr = recver.get_interface(network_name=make_net_name(recver.get_site())).get_ip_addr()\n",
    "print(f\"Sender sending from {sender_addr}, receiver receiving on {recver_addr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a3dcd-c367-4240-9cea-f2bbb45b2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e2sar_perf only the data= part of the query is meaningful. sync= must be present but is ignored\n",
    "# same for gRPC token, address and port (and lb id)\n",
    "e2sarPerfURI = f\"ejfat://useless@10.10.10.10:1234/lb/1?data={recver_addr}&sync=192.168.77.7:1234\"\n",
    "recverDuration = 30\n",
    "mtu = 9000\n",
    "rate = 10 # Gbps\n",
    "length = 1000000 # event length in bytes\n",
    "numEvents = 10000 # number of events to send\n",
    "bufSize = 300 * 1024 * 1024 # 100MB send and receive buffers\n",
    "recvThreads = 1 # makes no sense to use more than one in this scenario\n",
    "coreList = \"1\" # space-separated list of cores\n",
    "dequeThreads = 1 # threads that remove reassembled events off queue\n",
    "useCoreList = False\n",
    "\n",
    "if not useCoreList:\n",
    "    # without thread affinity\n",
    "    recv_command = f\"cd E2SAR; PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/ ./build/bin/e2sar_perf -r -u '{e2sarPerfURI}' -d {recverDuration} -b {bufSize} --ip {recver_addr} --port 19522 --deq {dequeThreads} --threads {recvThreads}\"\n",
    "else:\n",
    "    # with thread affinity\n",
    "    recv_command = f\"cd E2SAR; PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/ ./build/bin/e2sar_perf -r -u '{e2sarPerfURI}' -d {recverDuration} -b {bufSize} --ip {recver_addr} --port 19522 --deq {dequeThreads} --cores {coreList}\"\n",
    "\n",
    "send_command = f\"cd E2SAR; PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/ ./build/bin/e2sar_perf -s -u '{e2sarPerfURI}' --mtu {mtu} --rate {rate} --length {length} -n {numEvents} -b {bufSize} --ip {sender_addr}\"\n",
    "\n",
    "# start the receiver for N seconds and log its output\n",
    "print(f'Executing command {recv_command} on receiver')\n",
    "recver.execute_thread(recv_command, output_file=f\"{recver.get_name()}.perf.log\")\n",
    "\n",
    "# sleep 2 seconds to let receiver get going\n",
    "time.sleep(5)\n",
    "\n",
    "# start the sender in the foreground\n",
    "print(f'Executing command {send_command} on sender')\n",
    "stdout_send, stderr_send = sender.execute(send_command, output_file=f\"{sender.get_name()}.perf.log\")\n",
    "\n",
    "print(f\"Inspect {recver.get_name()}.perf.log file in your Jupyter container to see the results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c04a61-eebd-4189-9848-1c787995919e",
   "metadata": {},
   "source": [
    "### Reserve the Load Balancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e7e6b-dfd3-44b8-9d92-1df7b9887cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejfat admin URI is set in the preamble\n",
    "\n",
    "lb_path = './E2SAR/build/bin'\n",
    "ld_library_path = \"LD_LIBRARY_PATH=/usr/local/lib\"\n",
    "bin_path = \"PATH=./E2SAR/build/bin:$PATH\"\n",
    "# note we are forcing IPv4 here with -4 option - from FABRIC this is necessary\n",
    "lbadm = f\"{ld_library_path} {bin_path} lbadm -4\"\n",
    "e2sar_perf = f\"{ld_library_path} {bin_path} e2sar_perf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95678748-722e-4e95-8b2c-c2363dc523d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an overview command to see what is reserved\n",
    "# we use sender node but any node can be used for admin commands\n",
    "\n",
    "command = f\"{lbadm} --overview -u {ejfat_admin_uri}\"\n",
    "\n",
    "execute_commands(sender, [command])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96478f5-ca90-4ad7-9544-56330f59e8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve the load balancer\n",
    "lbname = 'e2sar-testlb'\n",
    "duration = '02:00:00' # 2 hours\n",
    "\n",
    "command = f\"{lbadm} --reserve -l {lbname} -a '{sender_addr}' -d {duration} -u '{ejfat_admin_uri}' -e\"\n",
    "execute_commands(sender, [command])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd72bab-8255-486d-a9cd-f753a8a707dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the 'Updated URI after reserve with instance token' from the above result here:\n",
    "instance_uri = 'ejfats://<replace with output from previous command>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed79af-9715-4fe5-b416-b769bb69503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the status of the reserved LB (as a check)\n",
    "command = f\"{lbadm} --status -u '{instance_uri}'\"\n",
    "execute_commands(sender, [command])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e0c89c-73e0-4d2c-a963-9ba405ba255b",
   "metadata": {},
   "source": [
    "### Run a test with real load balancer and single sender node and single receiver node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e762e-3945-4b74-8a88-91d49b16eaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select sender and receiver\n",
    "sender = list(filter(lambda n: n.get_name()[0:6] == \"Sender\", slice.get_nodes()))[0]\n",
    "recver = list(filter(lambda n: n.get_name()[0:7] == \"Worker1\", slice.get_nodes()))[0]\n",
    "\n",
    "sender_addr = sender.get_interface(network_name=make_net_name(sender.get_site())).get_ip_addr()\n",
    "recver_addr = recver.get_interface(network_name=make_net_name(recver.get_site())).get_ip_addr()\n",
    "print(f\"Sender sending from {sender_addr}, receiver receiving on {recver_addr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a206ef22-bb58-48ed-a1e8-9673e0a7d3b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run sender and receiver through the reserved LB\n",
    "recverDuration = 60\n",
    "mtu = 9000\n",
    "rate = 10 # Gbps\n",
    "length = 1000000 # event length in bytes\n",
    "numEvents = 20000 # number of events to send\n",
    "bufSize = 300 * 1024 * 1024 # 100MB send and receive buffers\n",
    "recvThreads = 6\n",
    "coreList = \"1 2 3 4 5 6\"\n",
    "dequeThreads = 1\n",
    "useCoreList = False\n",
    "\n",
    "# Some notable options:\n",
    "# Sender:\n",
    "# -z - send 0 event rate in Sync messages\n",
    "# --seq - use sequential numbers as LB and Sync event numbers \n",
    "# Receiver:\n",
    "# --deq - number of threads reading events off reassembly queue\n",
    "# --cores - list of cores to bind receiver threads to\n",
    "\n",
    "# Given that in FABRIC ejfat-lb.es.net resolves to IP6 first and gRPC C++ library doesn't\n",
    "# offer granular control over which resolved address is used, we use -4 option together with\n",
    "# --withcp to tell the code to use the IPv4 address, but this also disables cert validation.\n",
    "\n",
    "send_command = f\"{e2sar_perf} -s -u '{instance_uri}' --mtu {mtu} --rate {rate} --length {length} -n {numEvents} -b {bufSize} --ip {sender_addr} --withcp -4\"\n",
    "\n",
    "# we can receive with threads bound to cores (vCPUs) or not\n",
    "if not useCoreList:\n",
    "    recv_command = f\"{e2sar_perf} -r -u '{instance_uri}' -d {recverDuration} -b {bufSize} --ip {recver_addr} --port 10000 --withcp -4 --threads {recvThreads}\"\n",
    "else:\n",
    "    recv_command = f\"{e2sar_perf} -r -u '{instance_uri}' -d {recverDuration} -b {bufSize} --ip {recver_addr} --port 10000 --withcp -4 --cores {coreList}\"\n",
    "\n",
    "# start the receiver for n seconds and log its output\n",
    "print(f'Executing command {recv_command} on receiver')\n",
    "recver.execute_thread(recv_command, output_file=f\"{recver.get_name()}.perf.log\")\n",
    "\n",
    "# sleep 5 seconds to let receiver get going\n",
    "time.sleep(6)\n",
    "\n",
    "# start the sender in the foreground\n",
    "print(f'Executing command {send_command} on sender')\n",
    "stdout_send, stderr_send = sender.execute(send_command, output_file=f\"{sender.get_name()}.perf.log\")\n",
    "\n",
    "print(f\"Inspect {recver.get_name()}.perf.log file to see the results. It should indicate how many events were received and how many lost.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2842c38c-baac-4ad9-8caa-9fb994a92b6d",
   "metadata": {},
   "source": [
    "### Run the test with a single sender node and multiple receiver nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7477f90a-864b-43ef-ab66-16c379fb26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select sender and receivers\n",
    "sender = list(filter(lambda n: n.get_name()[0:6] == \"Sender\", slice.get_nodes()))[0]\n",
    "\n",
    "worker_index = 1\n",
    "recvers = list()\n",
    "recver_addrs = list()\n",
    "while True:\n",
    "    matches = list(filter(lambda n: n.get_name()[0:7] == f\"Worker{worker_index}\", slice.get_nodes()))\n",
    "    if len(matches) == 0:\n",
    "        break\n",
    "    recver = matches[0]\n",
    "    recvers.append(recver)\n",
    "    recver_addr = recver.get_interface(network_name=make_net_name(recver.get_site())).get_ip_addr()\n",
    "    recver_addrs.append(recver_addr)\n",
    "    worker_index += 1\n",
    "    \n",
    "sender_addr = sender.get_interface(network_name=make_net_name(sender.get_site())).get_ip_addr()\n",
    "print(f\"Sender sending from {sender_addr}, receivers receiving on:\")\n",
    "for recver, recver_addr in zip(recvers, recver_addrs):\n",
    "    print(\"\\t\" + recver.get_name() + \": \" + recver_addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8266a685-437f-4e13-8603-1bd550e900c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run sender and receivers through the reserved LB\n",
    "recverDuration = 60\n",
    "mtu = 9000\n",
    "rate = 20 # Gbps\n",
    "length = 1000000 # event length in bytes\n",
    "numEvents = 20000 # number of events to send\n",
    "bufSize = 300 * 1024 * 1024 # 100MB send and receive buffers\n",
    "recvThreads = 6 # on each receiver\n",
    "numSocks = 4 # number send sockets in sender\n",
    "startPort = 10000 # receiver starting port\n",
    "dequeThreads = 1\n",
    "\n",
    "# Some notable options:\n",
    "# Sender:\n",
    "# -z - send 0 event rate in Sync messages\n",
    "# --seq - use sequential numbers as LB and Sync event numbers \n",
    "# Receiver:\n",
    "# --deq - number of threads reading events off reassembly queue\n",
    "# --cores - list of cores to bind receiver threads to\n",
    "\n",
    "# Given that in FABRIC ejfat-lb.es.net resolves to IP6 first and gRPC C++ library doesn't\n",
    "# offer granular control over which resolved address is used, we use -4 option together with\n",
    "# --withcp to tell the code to use the IPv4 address, but this also disables cert validation.\n",
    "\n",
    "send_command = f\"{e2sar_perf} -s -u '{instance_uri}' --mtu {mtu} --rate {rate} --length {length} -n {numEvents} -b {bufSize} --ip {sender_addr} --sockets {numSocks} --withcp -4\"\n",
    "\n",
    "for recver, recver_addr in zip(recvers, recver_addrs):\n",
    "    recv_command = f\"{e2sar_perf} -r -u '{instance_uri}' -d {recverDuration} -b {bufSize} --ip {recver_addr} --port {startPort} --withcp -4 --threads {recvThreads} --deq {dequeThreads}\"\n",
    "    print(f'Executing command {recv_command} on receiver {recver.get_name()}')\n",
    "    recver.execute_thread(recv_command, output_file=f\"{recver.get_name()}.perf.log\")\n",
    "\n",
    "# sleep 5 seconds to let receivers get going\n",
    "time.sleep(5)\n",
    "\n",
    "# start the sender in the foreground\n",
    "print(f'Executing command {send_command} on sender')\n",
    "stdout_send, stderr_send = sender.execute(send_command, output_file=f\"{sender.get_name()}.perf.log\")\n",
    "\n",
    "print(f\"Inspect WorkerX.perf.log files to see the results. They should indicate how many events were received and how many lost.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41716952-8d5c-4eae-a843-ef5ac0c3ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free the load balancer\n",
    "command = f\"{lbadm} --free -u '{instance_uri}'\"\n",
    "\n",
    "execute_commands(sender, [command])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c8d476-689a-4c4c-b5dc-ed0625410abc",
   "metadata": {},
   "source": [
    "## Manage the slice\n",
    "\n",
    "### Extend by two weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf9fe4f-b067-4d2c-94a5-9839d5a53b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set end host to now plus 14 days\n",
    "end_date = (datetime.now(timezone.utc) + timedelta(days=14)).strftime(\"%Y-%m-%d %H:%M:%S %z\")\n",
    "\n",
    "try:\n",
    "    slice = fablib.get_slice(name=slice_name)\n",
    "\n",
    "    slice.renew(end_date)\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb476a-2b17-4064-9a0e-a7a98d865804",
   "metadata": {},
   "source": [
    "### Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3546bf-a013-4eaa-bab1-fb52f7d36c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(slice_name)\n",
    "slice.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d7e55-1ab7-42e7-9db4-b6b3e96b5f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
