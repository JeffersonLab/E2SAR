{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b8f888-5788-4dfe-ad0a-cb5b0e567188",
   "metadata": {},
   "source": [
    "# EJFAT LB Control Plane Tester\n",
    "\n",
    "This notebook stands up a slice of 3 nodes - sender, receiver and cpnode. The control plane daemon is deployed on the `cpnode` node in a 'mock' configuration (with no FPGA). DAQ and worker node code can be deployed on `sender` and `receiver` nodes for testing. The slice uses 'shared' and is created within a single FABRIC site for simplicity. It uses a single L2 bridge connection with RFC1918 IPv4 addressing, allowing all nodes to talk to each other. It is possible to run the dataplane assuming a single worker can keep up with a single sender since no actual load balancer is present in this configuration.\n",
    "\n",
    "Slice example:\n",
    "\n",
    "<div>\n",
    "    <img src=\"figs/UDP LB Control Plane Testing slice.png\" width=500>\n",
    "</div>\n",
    "\n",
    "## Preparation and overview\n",
    "\n",
    "- Be sure to [generate a keypair for Jupyter Hub](GitHubSSH.ipynb) and register it with GitHub - the keys will be used to check out the code from private repositories, like [UDPLBd](https://github.com/esnet/udplbd) and [E2SAR](https://github.com/JeffersonLab/E2SAR).\n",
    "- Note that for E2SAR development and testing sender and receiver node compile/build environments will be setup via post-boot scripts ([sender](post-boot/sender.sh) and [receiver](post-boot/recver.sh)) and grpc++ is installed as a tar.gz with static and dynamic libraries compiled for ubuntu22\n",
    "- This does not setup the control plane node for anything, but testing a specific version - you can set which branch of UDPLBd to check out and a containerized version is built and stood up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0bb3e-52ed-48c7-98ae-b51e62af39e4",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "This cell must be executed whether you are creating a new slice or continuing work on the old one. If you are continuing work, you then skip the slice create section and proceed to wherever you left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a3378-dd68-4685-b0d2-4cae8ad462b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# EDIT THIS\n",
    "#\n",
    "# if you want to force a site instead of using random\n",
    "# Pick 'UCSD', 'SRI', 'FIU' or 'TOKY' - these sites have\n",
    "# IPv4. Other sites use IPv6 management and have trouble\n",
    "# retrieving git-lfs artifacts.\n",
    "site_override = 'SRI'\n",
    "#site_override = None\n",
    "\n",
    "# GitHub SSH key file (private) registered using the GitHubSSH.ipynb notebook referenced above\n",
    "github_key = '/home/fabric/work/fabric_config/github_ecdsa'\n",
    "\n",
    "# branches for UDPLBd and E2SAR that we want checked out on the VMs\n",
    "udplbd_branch = 'develop'\n",
    "e2sar_branch = 'main'\n",
    "\n",
    "# which of the available config files to use with UDPLBd\n",
    "udplbd_config = 'lb_mock-tls.yml'\n",
    "\n",
    "# base distro 'ubuntu' or 'rocky'\n",
    "distro_name = 'ubuntu'\n",
    "\n",
    "binary_extension = {\n",
    "    'ubuntu': 'ubuntu22',\n",
    "    'rocky': 'rocky8'\n",
    "}[distro_name]\n",
    "\n",
    "# note that the below is distribution specific ('ubuntu' for ubuntu and so on)\n",
    "home_location = {\n",
    "    'ubuntu': '/home/ubuntu',\n",
    "    'rocky' : '/home/rocky'\n",
    "}[distro_name]\n",
    "\n",
    "vm_key_location = f'{home_location}/.ssh/github_ecdsa'\n",
    "\n",
    "# grpc tar ball stored in E2SAR repo (via LFS)\n",
    "grpc_tar = f\"grpc-v1.54.1-{binary_extension}.tar.gz\"\n",
    "boost_tar = f\"boost-v1.85.0-{binary_extension}.tar.gz\"\n",
    "\n",
    "# which test suites in E2SAR to run (leave empty to run all)\n",
    "# you can set 'unit' or 'live' to run unit or live tests only\n",
    "e2sar_test_suite = ''\n",
    "\n",
    "# name of the network connecting the nodes\n",
    "net_name = 'site_bridge_net'\n",
    "\n",
    "\n",
    "#\n",
    "# SHOULDN'T NEED TO EDIT BELOW\n",
    "#\n",
    "# Preamble\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from datetime import timedelta\n",
    "\n",
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "\n",
    "from ipaddress import ip_address, IPv4Address, IPv6Address, IPv4Network, IPv6Network\n",
    "import ipaddress\n",
    "\n",
    "fablib = fablib_manager()             \n",
    "fablib.show_config();\n",
    "\n",
    "images = {\n",
    "    'ubuntu': ('default_ubuntu_22', 'docker_ubuntu_22'),\n",
    "    'rocky': ('default_rocky_8', 'docker_rocky_8')\n",
    "}\n",
    "\n",
    "# variable settings\n",
    "slice_name = f'UDP LB Control Plane Testing with udplbd[{udplbd_branch}], e2sar[{e2sar_branch}] on {distro_name}'\n",
    "\n",
    "# for each node specify IP address (assuming /24), OS image\n",
    "# note that most of the keys in these dictionaries map directly\n",
    "# onto parameters to add_node()\n",
    "node_config = {\n",
    "    'sender': {\n",
    "        'ip':'192.168.0.1', \n",
    "        'image': images[distro_name][0],\n",
    "        'cores': 8,\n",
    "        'ram': 24,\n",
    "        'disk': 100 },\n",
    "    'recver': {\n",
    "        'ip':'192.168.0.2', \n",
    "        'image':images[distro_name][0],\n",
    "        'cores':8,\n",
    "        'ram': 24,\n",
    "        'disk': 100 },\n",
    "    'cpnode': {\n",
    "        'ip':'192.168.0.3', \n",
    "        'image':images[distro_name][1],\n",
    "        'cores':8,\n",
    "        'ram': 8,\n",
    "        'disk': 100 },\n",
    "}\n",
    "# skip these keys as they are not part of add_node params\n",
    "skip_keys = ['ip']\n",
    "# this is the NIC to use\n",
    "nic_model = 'NIC_Basic'\n",
    "# the subnet should match IPs\n",
    "subnet = IPv4Network(\"192.168.1.0/24\")\n",
    "\n",
    "def execute_single_node(node, commands):\n",
    "    for command in commands:\n",
    "        print(f'\\tExecuting \"{command}\" on node {node.get_name()}')\n",
    "        #stdout, stderr = node.execute(command, quiet=True, output_file=node.get_name() + '_install.log')\n",
    "        stdout, stderr = node.execute(command)\n",
    "    if not stderr and len(stderr) > 0:\n",
    "        print(f'Error encountered with \"{command}\": {stderr}')\n",
    "        \n",
    "def execute_commands(node, commands):\n",
    "    if isinstance(node, list):\n",
    "        for n in node:\n",
    "            execute_single_node(n, commands)\n",
    "    else:\n",
    "        execute_single_node(node, commands)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b813d-21d5-4b18-a3f7-fd0f9f4d42c8",
   "metadata": {},
   "source": [
    "## Create the slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dbf90d-5990-4453-9ae9-3def21b5910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all slices I have running\n",
    "output_dataframe = fablib.list_slices(output='pandas')\n",
    "if output_dataframe:\n",
    "    print(output_dataframe)\n",
    "else:\n",
    "    print('No active slices under this project')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a6afb-78de-4251-81ba-d65cac091028",
   "metadata": {},
   "source": [
    "If your slice is already active you can skip to the 'Get Slice Details' section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f956da26-1ebe-403b-a0aa-eedca260807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available images (this step is optional)\n",
    "available_images = fablib.get_image_names()\n",
    "\n",
    "print(f'Available images are: {available_images}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415878c8-815b-4b3d-a1df-65ec5bc5f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find an available site in continental US\n",
    "lon_west=-124.3993243\n",
    "lon_east=-69.9721573\n",
    "\n",
    "# getting a random site make take a bit of time\n",
    "if not site_override:\n",
    "    selected_site = fablib.get_random_site(filter_function=lambda x: x['location'][1] < lon_east\n",
    "                                              and x['location'][1] > lon_west) \n",
    "else:\n",
    "    selected_site = site_override\n",
    "\n",
    "if selected_site:\n",
    "    print(f'Selected site is {selected_site}')\n",
    "else:\n",
    "    print('Unable to find a site matching the requirements')\n",
    "\n",
    "# write selected site into node attributes\n",
    "for n in node_config:\n",
    "    node_config[n]['site'] = selected_site\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b7969-df0d-4c8e-b909-acc30dc8c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a slice\n",
    "slice = fablib.new_slice(name=slice_name)\n",
    "\n",
    "# create a network\n",
    "net1 = slice.add_l2network(name=net_name, subnet=subnet)\n",
    "\n",
    "nodes = dict()\n",
    "# create  nodes for sending and receiving with a selected network card\n",
    "# use subnet address assignment\n",
    "for node_name, node_attribs in node_config.items():\n",
    "    print(f\"{node_name=} {node_attribs['ip']}\")\n",
    "    nodes[node_name] = slice.add_node(name=node_name, **{x: node_attribs[x] for x in node_attribs if x not in skip_keys})\n",
    "    nic_interface = nodes[node_name].add_component(model=nic_model, name='_'.join([node_name, nic_model, 'nic'])).get_interfaces()[0]\n",
    "    net1.add_interface(nic_interface)\n",
    "    nic_interface.set_mode('config')\n",
    "    nic_interface.set_ip_addr(node_attribs['ip'])\n",
    "    # postboot configuration is under 'post-boot' directory\n",
    "    nodes[node_name].add_post_boot_upload_directory('post-boot','.')\n",
    "    nodes[node_name].add_post_boot_execute(f'chmod +x post-boot/{node_name}.sh && ./post-boot/{node_name}.sh')\n",
    "\n",
    "print(f'Creating a {distro_name} based slice named \"{slice_name}\" with nodes in {selected_site}')\n",
    "\n",
    "# Submit the slice\n",
    "slice.submit();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0ef1ea-11b0-4eeb-9ca7-a4a6fba7fb4c",
   "metadata": {},
   "source": [
    "## Get Slice Details\n",
    "\n",
    "If not creating a new slice, and just continuing work on an existing one, execute this cell (in addition to the preamble) and then any of the cells below will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c4bf4-f5e6-42d8-9994-b513e9762d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get slice details (if not creating new)\n",
    "slice = fablib.get_slice(name=slice_name)\n",
    "a = slice.show()\n",
    "nets = slice.list_networks()\n",
    "nodes = slice.list_nodes()\n",
    "\n",
    "cpnode = slice.get_node(name=\"cpnode\")    \n",
    "sender = slice.get_node(name=\"sender\")\n",
    "recver = slice.get_node(name=\"recver\")\n",
    "\n",
    "\n",
    "# get node dataplane addresses\n",
    "cpnode_addr = cpnode.get_interface(network_name=net_name).get_ip_addr()\n",
    "sender_addr = sender.get_interface(network_name=net_name).get_ip_addr()\n",
    "recver_addr = recver.get_interface(network_name=net_name).get_ip_addr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa3cdec-49f9-4c3c-89f8-b441e37d6302",
   "metadata": {},
   "source": [
    "## Start the UDPLBd container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a24024-c688-4100-b453-e34d0fe6ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any dockers are running already and that we have compose and buildx installed by post-boot script\n",
    "commands = [\n",
    "    'docker container ls',\n",
    "    'docker compose version',\n",
    "    'docker buildx version'\n",
    "]\n",
    "execute_commands(cpnode, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f156f84-6f00-4127-b563-58094206f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the mock config file for UDPLBd \n",
    "result = cpnode.upload_file(f'config/{udplbd_config}','lb_mock.yml')\n",
    "\n",
    "# upload the GitHub SSH key onto the VM\n",
    "result = cpnode.upload_file(github_key, vm_key_location)\n",
    "\n",
    "# checkout UDPLBd (including the right branch) using that key\n",
    "commands = [\n",
    "    f\"chmod go-rwx {vm_key_location}\",\n",
    "    f\"GIT_SSH_COMMAND='ssh -i {vm_key_location} -o IdentitiesOnly=yes -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no' git clone -b {udplbd_branch} git@github.com:esnet/udplbd.git\",\n",
    "]\n",
    "\n",
    "execute_commands(cpnode, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd079c-97cd-41cb-8358-509a81c6992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy configuration file into place, generate self-signed cert and start the UDPLBd container\n",
    "commands = [\n",
    "    f'cp lb_mock.yml ./udplbd/etc/config.yml',\n",
    "    f'openssl req -x509 -newkey rsa:4096 -keyout udplbd/etc/server_key.pem -out udplbd/etc/server_cert.pem -sha256 -days 365 -nodes -subj \"/CN=cpnode/subjectAltName=IP:{cpnode_addr}\" -nodes',\n",
    "    f'cd udplbd; docker compose up -d'\n",
    "]\n",
    "\n",
    "execute_commands(cpnode, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8d2487-e135-440b-9c43-4e6a65b06c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the logs\n",
    "commands = [\n",
    "    'docker compose ls',\n",
    "    'cd udplbd; docker compose logs'\n",
    "]\n",
    "\n",
    "execute_commands(cpnode, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a97579-1655-4970-b4bb-ea04a98aca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need to restart it, this is the stop part\n",
    "commands = [\n",
    "    'cd udplbd; docker compose stop; docker compose rm -f; docker image rm udplbd'\n",
    "]\n",
    "\n",
    "execute_commands(cpnode, commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c5e64-2a8c-443c-9f80-884b053ad6bf",
   "metadata": {},
   "source": [
    "## Clone E2SAR code into sender and receiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd9b8f-87b6-4150-b03a-81902b8fd9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install github ssh key and set up build environment variables for interactive logins\n",
    "commands = [\n",
    "    f\"chmod go-rwx {vm_key_location}\",\n",
    "    # Meson won't detect boost by merely setting cmake_prefix_path, instead set BOOST_ROOT env variable \n",
    "    # for gRPC it is enough to set -Dpkg_config_path option to meson\n",
    "    f\"echo 'export BOOST_ROOT=$HOME/boost-install PATH=$HOME/.local/bin:$HOME/grpc-install/bin:$PATH LD_LIBRARY_PATH=$HOME/grpc-install/lib/:$HOME/boost-install/lib' >> ~/.profile\",\n",
    "    f\"echo 'export BOOST_ROOT=$HOME/boost-install PATH=$HOME/.local/bin:$HOME/grpc-install/bin:$PATH LD_LIBRARY_PATH=$HOME/grpc-install/lib/:$HOME/boost-install/lib' >> ~/.bashrc\",\n",
    "]\n",
    "\n",
    "for node in [sender, recver]:    \n",
    "    # upload the GitHub SSH key onto the VM\n",
    "    result = node.upload_file(github_key, vm_key_location)\n",
    "    execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f3afc-f8cf-40f9-81c5-8eceffb1df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout E2SAR (including the right branch) using that key, install grpc and boost binary that is stored in the repo\n",
    "commands = [\n",
    "    f\"GIT_SSH_COMMAND='ssh -i {vm_key_location} -o IdentitiesOnly=yes -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no' git clone --recurse-submodules --depth 1 -b {e2sar_branch} git@github.com:JeffersonLab/E2SAR.git\",\n",
    "    f\"tar -zxf E2SAR/binary_artifacts/{grpc_tar}\",\n",
    "    f\"tar -zxf E2SAR/binary_artifacts/{boost_tar}\",\n",
    "    #f\"cd E2SAR; GIT_SSH_COMMAND='ssh -i {vm_key_location} -o IdentitiesOnly=yes -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no' git submodule init\",\n",
    "]\n",
    " \n",
    "execute_commands([sender, recver], commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed0ed9d-161e-4397-9bff-780dda436823",
   "metadata": {},
   "source": [
    "On RedHat/Rocky derivatives the build fails. Likely has to do with the outdated gcc/g++ and stdlib. E2SAR/build/ninja.build must be modified - all mentions of `-std=c++11` must be removed from it.\n",
    "\n",
    "To avoid this after the build step (and the next one after) the below command invokes `sed` to remove mentions of `c++11` from build.ninja file. This is a hack, don't just walk away, **RUN**!\n",
    "\n",
    "Also note that the install directory is set to `$(HOME)/e2sar-install`. So if you run `meson install -C build` this is where the code will end up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20babd62-72ca-4a7c-a167-b48fcc80633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build E2SAR code and run unit tests\n",
    "commands = [\n",
    "    f\"cd E2SAR; BOOST_ROOT=$HOME/boost-install PATH=$HOME/.local/bin:$HOME/grpc-install/bin:$PATH LD_LIBRARY_PATH=$HOME/grpc-install/lib/:$HOME/boost-install/lib meson setup -Dpkg_config_path=$HOME/grpc-install/lib/pkgconfig/:$HOME/grpc-install/lib64/pkgconfig/ --prefix {home_location}/e2sar-install build && sed -i 's/-std=c++11//g' build/build.ninja\",\n",
    "    f\"cd E2SAR/build; PATH=$HOME/.local/bin:$HOME/grpc-install/bin:$PATH LD_LIBRARY_PATH=$HOME/grpc-install/lib/:$HOME/boost-install/lib  meson compile -j 8\",\n",
    "    f\"cd E2SAR/build; EJFAT_URI='ejfats://udplbd@{cpnode_addr}:18347/lb/12?sync=192.168.100.10:19020&data=192.168.101.10:18020' PATH=$HOME/.local/bin:$HOME/grpc-install/bin:$PATH LD_LIBRARY_PATH=$HOME/grpc-install/lib/:$HOME/boost-install/lib  meson test {e2sar_test_suite} --suite unit  --timeout 0\",\n",
    "    f\"cd E2SAR/build; EJFAT_URI='ejfats://udplbd@{cpnode_addr}:18347/' PATH=$HOME/.local/bin:$HOME/grpc-install/bin:$PATH LD_LIBRARY_PATH=$HOME/grpc-install/lib/:$HOME/boost-install/lib  meson test {e2sar_test_suite} --suite live --timeout 0\"\n",
    "]\n",
    " \n",
    "execute_commands([sender, recver], commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd75340",
   "metadata": {},
   "source": [
    "Again, making sure we update ninja.build... Look away..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4fcb4e-9647-493b-9943-7587ffc650fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the code, compile and test\n",
    "\n",
    "commands = [\n",
    "    f\"cd E2SAR; GIT_SSH_COMMAND='ssh -i {vm_key_location} -o IdentitiesOnly=yes -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no' git pull origin {e2sar_branch}\",\n",
    "    f\"cd E2SAR; BOOST_ROOT=$HOME/boost-install PATH=$HOME/.local/bin:$HOME/grpc-install/bin:$PATH LD_LIBRARY_PATH=$HOME/grpc-install/lib/:$HOME/boost-install/lib meson setup -Dpkg_config_path=$HOME/grpc-install/lib/pkgconfig/:$HOME/grpc-install/lib64/pkgconfig/ --prefix {home_location}/e2sar-install build --wipe && sed -i 's/-std=c++11//g' build/build.ninja\",\n",
    "    f\"cd E2SAR/build; PATH=$HOME/.local/bin:/home/ubuntu/grpc-install/bin:$PATH LD_LIBRARY_PATH=$HOME/grpc-install/lib/:$HOME/boost-install/lib  meson compile -j 8\",\n",
    "    f\"cd E2SAR/build; EJFAT_URI='ejfats://udplbd@{cpnode_addr}:18347/lb/12?sync=192.168.100.10:19020&data=192.168.101.10:18020' PATH=$HOME/.local/bin:$HOME/grpc-install/bin:$PATH LD_LIBRARY_PATH=$HOME/grpc-install/lib/:$HOME/boost-install/lib  meson test {e2sar_test_suite} --suite unit --timeout 0\",\n",
    "    f\"cd E2SAR/build; EJFAT_URI='ejfats://udplbd@{cpnode_addr}:18347/' PATH=$HOME/.local/bin:$HOME/grpc-install/bin:$PATH LD_LIBRARY_PATH=$HOME/grpc-install/lib/:$HOME/boost-install/lib  meson test {e2sar_test_suite} --suite live --timeout 0\"\n",
    "]\n",
    "  \n",
    "execute_commands([sender, recver], commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a91bdf-ad59-45ab-b29c-1e1d3d4fa005",
   "metadata": {},
   "source": [
    "## Manage the slice\n",
    "\n",
    "### Extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c55dd8-6b83-4711-80e1-4d73d3de04d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set end host to now plus 14 days\n",
    "end_date = (datetime.now(timezone.utc) + timedelta(days=14)).strftime(\"%Y-%m-%d %H:%M:%S %z\")\n",
    "\n",
    "try:\n",
    "    slice = fablib.get_slice(name=slice_name)\n",
    "\n",
    "    slice.renew(end_date)\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd1dbd-d502-461b-ad40-c589d7e32826",
   "metadata": {},
   "source": [
    "### Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f88bb58-a197-4853-9294-c90e2b250cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(slice_name)\n",
    "slice.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b909f-107f-4ff6-9fe1-baa14377fffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
