{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69714ad3-0437-4971-8067-2cf91e75cf56",
   "metadata": {},
   "source": [
    "# Standing up EJFAT LB on a FABRIC U280-equipped node\n",
    "\n",
    "Your compute nodes can include FPGAs. These devices are made available as FABRIC components and can be added to your nodes like any other component. Your project must have Component.FPGA permission tag in order to be able to provision them. \n",
    "\n",
    "This notebook stands up a single VM with an attached U280 and starts up the necessary stacks on it to get the Load Balancer running. There is an optional set of steps in the middle to help build the needed docker containers. Alternatively they can be fetched from a storage VM on EDC (there is another notebook that shows how to stand it up - it is attached to a persistent storage volume that contains pre-built artifacts).\n",
    "\n",
    "<div>\n",
    "    <img src=\"figs/u280-slice.png\" width=500>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8a7247-578c-438c-9143-973a2adb3a47",
   "metadata": {},
   "source": [
    "## Setup the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4824ebf-e1f7-417c-a25e-60102a719332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "\n",
    "fablib = fablib_manager()\n",
    "                     \n",
    "fablib.show_config();\n",
    "\n",
    "\n",
    "# until fablib fixes this\n",
    "def get_management_os_interface(node) -> str or None:\n",
    "        \"\"\"\n",
    "        Gets the name of the management interface used by the node's\n",
    "        operating system. \n",
    "\n",
    "        :return: interface name\n",
    "        :rtype: String\n",
    "        \"\"\"\n",
    "        stdout, stderr = node.execute(\"sudo ip -j route list\", quiet=True)\n",
    "        stdout_json = json.loads(stdout)\n",
    "\n",
    "        for i in stdout_json:\n",
    "            if i[\"dst\"] == \"default\":\n",
    "                return i[\"dev\"]\n",
    "\n",
    "        stdout, stderr = node.execute(\"sudo ip -6 -j route list\", quiet=True)\n",
    "        stdout_json = json.loads(stdout)\n",
    "\n",
    "        for i in stdout_json:\n",
    "            if i[\"dst\"] == \"default\":\n",
    "                return i[\"dev\"]\n",
    "\n",
    "        return None\n",
    "\n",
    "def execute_single_node(node, commands):\n",
    "    for command in commands:\n",
    "        print(f'\\tExecuting \"{command}\" on node {node.get_name()}')\n",
    "        #stdout, stderr = node.execute(command, quiet=True, output_file=node.get_name() + '_install.log')\n",
    "        stdout, stderr = node.execute(command)\n",
    "    if not stderr and len(stderr) > 0:\n",
    "        print(f'Error encountered with \"{command}\": {stderr}')\n",
    "        \n",
    "def execute_commands(node, commands):\n",
    "    if isinstance(node, list):\n",
    "        for n in node:\n",
    "            execute_single_node(n, commands)\n",
    "    else:\n",
    "        execute_single_node(node, commands)\n",
    "\n",
    "def execute_single_node_on_thread(node, commands):\n",
    "    # concatenate the commands using ';' and execute\n",
    "    allcommands = ';'.join(commands)\n",
    "    node.execute_thread(allcommands, output_file=node.get_name() + '_thread.log')\n",
    "\n",
    "def execute_commands_on_threads(node, commands):\n",
    "    if isinstance(node, list):\n",
    "        for n in node:\n",
    "            execute_single_node_on_thread(n, commands)\n",
    "    else:\n",
    "        execute_single_node_on_thread(node, commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf0edc2-e71a-4df0-a7d0-60362e9b6089",
   "metadata": {},
   "source": [
    "## Select a site with E2SAR-assigned FPGA\n",
    "\n",
    "The cells below help you create a slice that contains a single node with an attached FPGA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4355ef6d-5977-4b22-b14e-2f9f5a05b0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which sites have available FPGAs on hosts (and also list memory, disk and core on those hosts)\n",
    "# Overall list of sites that are usable with ESnet workflow\n",
    "sites_to_check = ['STAR', 'TACC', 'MICH', 'UTAH', 'NCSA', 'WASH', 'DALL', 'SALT', 'UCSD', 'CLEM', 'LOSA', 'KANS', 'PRIN', 'SRI']\n",
    "# sites that were cleared for this project\n",
    "sites_to_check = ['LOSA', 'KANS', 'WASH']\n",
    "\n",
    "# worker name is <site in lower case>-w[0-9]+.fabric.net\n",
    "hosts = fablib.list_hosts(fields=['name','cores_available','ram_available','disk_available','fpga_u280_available'], \n",
    "                          filter_function=lambda s: (s['name'].split('-')[0].upper() in sites_to_check) and \n",
    "                          s['fpga_u280_capacity']>0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b608c78a-a185-4d5d-afa2-d34d328292c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend a site with availability\n",
    "ram = 32\n",
    "cores = 8\n",
    "disk = 100\n",
    "\n",
    "# hosts is a Styler over a DataFrame, we want to get the underlying numpy array\n",
    "recommended_sites = []\n",
    "for host in hosts.data.to_numpy():\n",
    "    if host[1] > cores and host[2] > ram and host[3] > disk and host[4] > 0:\n",
    "        recommended_sites.append(host[0].split('-')[0].upper())\n",
    "\n",
    "if recommended_sites is not None:\n",
    "    print(f'Recommended sites are {recommended_sites}')\n",
    "else:\n",
    "    print(f'Unable to find a usable site among {sites_to_check}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a78a65-2c33-4480-9b09-14eb61f0b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPGA site should only be one of these as these are assigned to the project\n",
    "# Pick one of the outcomes from recommended sites above\n",
    "site='KANS'\n",
    "\n",
    "FPGA_CHOICE='FPGA_Xilinx_U280'\n",
    "\n",
    "# name the slice and the node \n",
    "slice_name=f'E2SAR U280 LB Slice on {site}'\n",
    "\n",
    "fpga_node_name='LB-node'\n",
    "image = 'default_ubuntu_22'\n",
    "net_name = '_'.join(['fabnetv4', site])\n",
    "\n",
    "# storage VM - update this after you provision it using the other notebook\n",
    "storage_vm_ip = \"10.132.137.2\"\n",
    "nginx_user = \"fpga_tools\"\n",
    "nginx_password = \"changemenow123\"\n",
    "\n",
    "# version to use for saving docker images\n",
    "docker_image_version = \"12162024\"\n",
    "\n",
    "print(f'Will create slice \"{slice_name}\" with node \"{fpga_node_name}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f18dfb-1348-4802-a698-45d999be080a",
   "metadata": {},
   "source": [
    "## Create a slice with a node with FPGA at desired site\n",
    "\n",
    "This slice has one VM with an FPGA and a basic NIC to talk to the storage VM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21aa83f-79e4-4590-8d2b-929c1030095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Slice. Note that by default submit() call will poll for 360 seconds every 10-20 seconds\n",
    "# waiting for slice to come up. Normal expected time is around 2 minutes. \n",
    "slice = fablib.new_slice(name=slice_name)\n",
    "storage_nic_name = 'storage_nic'\n",
    "\n",
    "# Add node with a 100G drive and 8 of CPU cores using Ubuntu 22 image\n",
    "node = slice.add_node(name=fpga_node_name, site=site, cores=cores, ram=ram, disk=disk, image=image)\n",
    "# and a basic NIC to talk to storage\n",
    "iface1 = node.add_component(model='NIC_Basic', name=storage_nic_name).get_interfaces()[0]\n",
    "\n",
    "# postboot configuration is under 'post-boot' directory\n",
    "node.add_post_boot_upload_directory('post-boot','.')\n",
    "node.add_post_boot_execute(f'chmod +x post-boot/lb-node.sh && ./post-boot/lb-node.sh')\n",
    "# FABNetv4 on shared NIC (to talk to storage)\n",
    "#node.add_fabnet()\n",
    "\n",
    "fpga_comp = node.add_component(model=FPGA_CHOICE, name='fpga1')\n",
    "fpga_p1 = fpga_comp.get_interfaces()[0]\n",
    "fpga_p2 = fpga_comp.get_interfaces()[1]\n",
    "\n",
    "# use FABNetv4 to connect port 1 of FPGA and the basic NIC (yes it is the same network)\n",
    "net = slice.add_l3network(name=net_name, interfaces=[fpga_p1, iface1], type='IPv4')\n",
    "\n",
    "# Submit Slice Request\n",
    "slice.submit();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716310c6-1748-4ab6-b60a-60fbd19098da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get slice details. You can rerun this as many times as you want\n",
    "slice = fablib.get_slice(name=slice_name)\n",
    "node = slice.get_node(name=fpga_node_name)\n",
    "\n",
    "# we will use these IPs on the basic NIC and as a pool of IPv4 addresses for the\n",
    "# FPGA. Pool of FPGA IPv6 addresses will be fake in this scenario - we cannot attach\n",
    "# more than one network service to an interface\n",
    "network = slice.get_network(name=net_name)\n",
    "network_available_ips = list(network.get_subnet().hosts())\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab577b5-65cd-47a2-b60d-9d93ff495e9b",
   "metadata": {},
   "source": [
    "## Setup IOMMU and Hugepages\n",
    "For DPDK to function properly we need to setup hugepages and IOMMU on the VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a9ec37-7a93-4128-8d14-7af8e52fb0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure GRUB\n",
    "slice = fablib.get_slice(name=slice_name)\n",
    "node = slice.get_node(name=fpga_node_name)\n",
    "\n",
    "commands = list()\n",
    "#commands.append(\"sudo sed -i 's/GRUB_CMDLINE_LINUX=\\\"\\\\(.*\\\\)\\\"/GRUB_CMDLINE_LINUX=\\\"\\\\1 amd_iommu=on iommu=pt default_hugepagesz=1G hugepagesz=1G hugepages=8\\\"/' /etc/default/grub\")\n",
    "commands.append(\"sudo sed -i 's/GRUB_CMDLINE_LINUX=\\\"\\\"/GRUB_CMDLINE_LINUX=\\\"amd_iommu=on iommu=pt default_hugepagesz=1G hugepagesz=1G hugepages=8\\\"/' /etc/default/grub\")\n",
    "commands.append(\"sudo grub-mkconfig -o /boot/grub/grub.cfg\")\n",
    "commands.append(\"sudo update-grub\")\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ca099b-bf94-4dd1-b53d-a7fee5641be3",
   "metadata": {},
   "source": [
    "Reboot the node (this sometimes generates an EOFError exception - ignore it and continue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61775017-9d5c-42ad-a862-9dc6ba1f85b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reboot = 'sudo reboot'\n",
    "\n",
    "print(reboot)\n",
    "node.execute(reboot)\n",
    "\n",
    "slice.wait_ssh(timeout=360,interval=10,progress=True)\n",
    "\n",
    "print(\"Now testing SSH abilites to reconnect...\",end=\"\")\n",
    "slice.update()\n",
    "slice.test_ssh()\n",
    "print(\"Reconnected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfe1ab2-a975-4235-85a2-d7ad759144fd",
   "metadata": {},
   "source": [
    "Check that IOMMU was enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb04697-5da3-4aee-b7ef-94699fcfdf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'sudo dmesg | grep -i IOMMU'\n",
    "\n",
    "print('Observe that the modifications to boot configuration took place and IOMMU is detected')\n",
    "stdout, stderr = node.execute(command)\n",
    "\n",
    "node.config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c92785a-8c70-4b31-821a-f0e9ee88b489",
   "metadata": {},
   "source": [
    "Disable IOMMU support in VFIO (the passing through doesn't actually work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a7d00-9b04-4053-bc53-d80410912d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable unsafe_noiommu_mode for the vfio module\n",
    "command = \"echo 1 | sudo tee /sys/module/vfio/parameters/enable_unsafe_noiommu_mode\"\n",
    "\n",
    "stdout, stderr = node.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a68f964-661b-4fb3-b88c-c44f9856d0fb",
   "metadata": {},
   "source": [
    "## Configure the NIC interface for accessing storage and inbound control plane and get a pool of IPs for the FPGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe654d99-d469-4e8d-b0b8-423b305912ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress \n",
    "\n",
    "def get_valid_ips(ip_list, gateway, qty=1):\n",
    "    # make sure the returned IP isn't the gateway\n",
    "    ips = []\n",
    "    while qty > 0:\n",
    "        ip = ip_list.pop()\n",
    "        while ip == gateway:\n",
    "            ip = ip_list.pop()\n",
    "        ips.append(ip)\n",
    "        qty -= 1\n",
    "\n",
    "    return ips\n",
    "    \n",
    "storage_nic_ip = get_valid_ips(network_available_ips, network.get_gateway())[0]\n",
    "\n",
    "# number of fpga IP addresses we want\n",
    "fpga_ips_qty = 8\n",
    "\n",
    "fpga_ips = get_valid_ips(network_available_ips, network.get_gateway(), qty=fpga_ips_qty)\n",
    "\n",
    "print(f'Using this ip to talk to storage: {storage_nic_ip}')\n",
    "print(f'Using these IPs for FPGA IPv4 pool: {fpga_ips}')\n",
    "\n",
    "# FABRIC pretends to use /24, but really it is a /10 routable space\n",
    "site_subnet= network.get_subnet()\n",
    "full_subnet = ipaddress.IPv4Network('10.128.0.0/10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5205ec4b-e192-49d6-84fd-c3ebe2b817fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that we can't get an interface by network name as in this example both FPGA and Shared NIC \n",
    "# are hanging off the same network service\n",
    "node_iface = node.get_interface(name='-'.join([fpga_node_name, storage_nic_name, 'p1']))\n",
    "print(f'Configuring interface {node_iface.get_name()}')\n",
    "node_iface.ip_addr_add(addr=storage_nic_ip, subnet=site_subnet)\n",
    "node.ip_route_add(subnet=full_subnet, gateway=network.get_gateway())\n",
    "commands = [\n",
    "    \"ip a\",\n",
    "    \"ip r\"\n",
    "]\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cac068-c1e9-478b-9ebe-4f951fd9cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since firewalld is running, lets tell it all interfaces are trusted\n",
    "# WATCH OUT FOR WHAT IS TYPICALLY enp7s0 (data interface) SPONTANEOUSLY CHANGING ITS NAME\n",
    "# IF THIS HAPPENS YOU MIGHT SEE REPORTED ROUTING PROBLEMS, BUT  IT IS THE FIREWALL\n",
    "mgmt_iface_name = get_management_os_interface(node)\n",
    "data_iface = node.get_interface(network_name=network.get_name())\n",
    "data_iface_name = data_iface.get_os_interface()\n",
    "commands = [\n",
    "    f'sudo firewall-cmd --permanent --zone=trusted --add-interface={data_iface_name}',\n",
    "    f'sudo firewall-cmd --permanent --zone=trusted --add-interface=lo',\n",
    "    f'sudo firewall-cmd --permanent --zone=trusted --add-interface={mgmt_iface_name}',\n",
    "    f'for i in $(sudo firewall-cmd --zone=public --list-services); do sudo firewall-cmd --zone=public --permanent --remove-service=$i; done',\n",
    "]\n",
    "commands.append(f'sudo firewall-cmd --reload')\n",
    "commands.append(f'sudo firewall-cmd --list-all --zone=trusted')\n",
    "\n",
    "execute_commands([node], commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2f383a-5e4e-4771-86b4-22a7742540fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test connectivity to storage node\n",
    "commands = [\n",
    "    f\"sudo ping -q -f -c 100 {storage_vm_ip}\"\n",
    "]\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879ad03e-459a-42c7-ac9f-499a8efbf437",
   "metadata": {},
   "source": [
    "## Update Docker daemon configuration to make sure builds work on IPv6 hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be66a6d3-55cd-4c18-86c3-6b3011cedcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "node.upload_file('config/daemon.json', 'daemon.json')\n",
    "commands = [\n",
    "    \"sudo mv daemon.json /etc/docker/; sudo chown root:root /etc/docker/daemon.json\",\n",
    "    \"sudo systemctl restart docker\",\n",
    "    \"sudo systemctl status docker\"\n",
    "]\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ebded-0471-4b2e-815c-112131acbbc3",
   "metadata": {},
   "source": [
    "## Build the docker containers and upload to storage VM (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80514dd7-32fb-4c91-af7f-cc04a9145256",
   "metadata": {},
   "source": [
    "We have to build 3 container images:\n",
    "- xilinx-labtools-docker (requires Xilinx labtools)\n",
    "- smartnic-dpdk-docker \n",
    "- esnet-smartnic-fw (requires P4 artifact from ESnet team)\n",
    "\n",
    "These are `docker compose`d together into a running stack. In addition UDPLBd must be run on top of this stack to provide the control plane functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf8714-7a8f-4fa5-8a75-20107a6ea33e",
   "metadata": {},
   "source": [
    "### Building xilinx-labtools-docker container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4593c5f5-309c-451a-aabb-f5d0a8371464",
   "metadata": {},
   "source": [
    "Following these instructions:\n",
    "- https://github.com/esnet/xilinx-labtools-docker/\n",
    "\n",
    "Overall steps are:\n",
    "- Checkout the repo https://github.com/esnet/xilinx-labtools-docker/\n",
    "- Download the missing files from Storage VM\n",
    "- Run docker build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d1c9d8-f2a6-44fc-87b5-5b2ad24ee567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a map between destination directory names and files. On the storage VM all files are in the same directory\"\n",
    "fetch_file_list = {\n",
    "    \"sc-fw-downloads\": [\"SC_U280_4_3_31.zip\", \"SC_U55C_7_1_23.zip\", \"loadsc_v2.3.zip\"],\n",
    "    \"vivado-installer\": [\"Vivado_Lab_Lin_2023.2_1013_2256.tar.gz\"]\n",
    "}\n",
    "commands = [\n",
    "    \"rm -rf xilinx-labtools-docker\",\n",
    "    f\"git clone https://github.com/esnet/xilinx-labtools-docker.git\"\n",
    "]\n",
    "\n",
    "curl_command = f\"curl -s -k -u {nginx_user}:{nginx_password} https://{storage_vm_ip}/ejfat-data/artifacts/Vivado-Labtools/\"\n",
    "\n",
    "for ddir, filelist in fetch_file_list.items():\n",
    "    for file in filelist:\n",
    "        commands.append(f\"{curl_command}{file} > {file}\")\n",
    "        commands.append(f\"mv {file} xilinx-labtools-docker/{ddir}\")\n",
    "          \n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257426ee-7162-40e3-83ad-9e9ce41b859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build step\n",
    "\n",
    "commands = [\n",
    "    \"cd xilinx-labtools-docker; docker build --pull -t xilinx-labtools-docker:${USER}-dev .\",\n",
    "    \"docker image ls\"\n",
    "]\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4007e-2061-4755-bba8-54aa90adb9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image to file and upload to the storage VM\n",
    "commands = [\n",
    "    f\"docker save xilinx-labtools-docker | gzip > xilinx-labtools-docker-{docker_image_version}.tar.gz\",\n",
    "    f\"curl -s -k -u {nginx_user}:{nginx_password} -T xilinx-labtools-docker-{docker_image_version}.tar.gz https://{storage_vm_ip}/ejfat-data/smartnic-docker-images/\"\n",
    "]\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbdf432-2455-46ef-a82e-113ad8119157",
   "metadata": {},
   "source": [
    "### Building smartnic-dpdk-docker container\n",
    "\n",
    "Following these instructions\n",
    "- https://github.com/esnet/smartnic-dpdk-docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae99b86-3757-405f-b418-e4dea969801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone\n",
    "commands = [\n",
    "    \"rm -rf smartnic-dpdk-docker\",\n",
    "    \"git clone https://github.com/esnet/smartnic-dpdk-docker.git\",\n",
    "    \"cd smartnic-dpdk-docker; git submodule update --init --recursive\"\n",
    "]\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7801b818-7b1d-4c68-8a89-c58840396884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build step\n",
    "\n",
    "commands = [\n",
    "    \"cd smartnic-dpdk-docker; docker build --pull -t smartnic-dpdk-docker:${USER}-dev .\",\n",
    "    \"docker image ls\"\n",
    "]\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d27eed-3c55-40b7-957a-016de81ef296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image to file and upload to the storage VM\n",
    "commands = [\n",
    "    f\"docker save smartnic-dpdk-docker | gzip > smartnic-dpdk-docker-{docker_image_version}.tar.gz\",\n",
    "    f\"curl -s -k -u {nginx_user}:{nginx_password} -T smartnic-dpdk-docker-{docker_image_version}.tar.gz https://{storage_vm_ip}/ejfat-data/smartnic-docker-images/\"\n",
    "]\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f82e6ce-cc9b-4c68-9ddb-82e4eea8cc90",
   "metadata": {},
   "source": [
    "### Building esnet-smartnic-fw container\n",
    "\n",
    "Following these instructions:\n",
    "- https://github.com/esnet/esnet-smartnic-fw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e583e5-a367-48e3-86f5-c83a4d7ccba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone. You need to do this step even if you've built this before, sn-stack/ gets untarred into this.\n",
    "\n",
    "# optionally use a specific commit\n",
    "commit_hash = None\n",
    "#commit_hash = \"640b63981413f7fb5daef6e140c1e1896beff75f\"\n",
    "\n",
    "commands = [\n",
    "    \"rm -rf esnet-smartnic-fw\",\n",
    "    \"git clone https://github.com/esnet/esnet-smartnic-fw.git\",\n",
    "    \"cd esnet-smartnic-fw; git submodule init && git submodule update\"\n",
    "]\n",
    "\n",
    "if commit_hash is not None:\n",
    "    commands.append(f\"cd esnet-smartnic-fw; git checkout {commit_hash}\")\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d68bd5d-9e17-4dca-a18a-a7fef372c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the P4 artifact and install in the right place\n",
    "\n",
    "# this is the hardware version that is part of the bitfile file name\n",
    "sn_hw_ver=\"57684\"\n",
    "p4_artifact = f\"artifacts.au280.udplb.{sn_hw_ver}.zip\"\n",
    "\n",
    "commands = [\n",
    "    f\"curl -s -k -u {nginx_user}:{nginx_password} https://{storage_vm_ip}/ejfat-data/artifacts/P4/{p4_artifact} > {p4_artifact}\",\n",
    "    f\"mv {p4_artifact} esnet-smartnic-fw/sn-hw\"\n",
    "]\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b810524-63ad-4e58-967a-59690148c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an env file for the build\n",
    "# if the P4 bitfile was called artifacts.au280.udplb.57684.zip, then\n",
    "# SN_HW_VER=57684\n",
    "# SN_HW_BOARD=au280 \n",
    "# SN_HW_APP_NAME=udplb\n",
    "\n",
    "env_file = f\"\"\"\n",
    "SN_HW_VER={sn_hw_ver}\n",
    "SN_HW_BOARD=au280\n",
    "SN_HW_APP_NAME=udplb\n",
    "\"\"\"\n",
    "\n",
    "commands = [\n",
    "    f\"cd esnet-smartnic-fw; rm -f .env; cp example.env .env\",\n",
    "    f\"echo '{env_file}' >> ~/esnet-smartnic-fw/.env\"\n",
    "]\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdd3b1-5cc0-4b4e-b55b-e52834b3fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the build\n",
    "\n",
    "commands = [\n",
    "    f\"cd esnet-smartnic-fw; ./build.sh\",\n",
    "    f\"docker image ls\"\n",
    "]\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc494c-140f-4607-b286-599c721fdf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image to file and upload to the storage VM\n",
    "# also tar up the sn-stack/ directory and ship to storage VM\n",
    "commands = [\n",
    "    f\"docker save esnet-smartnic-fw | gzip > esnet-smartnic-fw-{docker_image_version}.tar.gz\",\n",
    "    f\"cd esnet-smartnic-fw; tar -zcf sn-stack-{docker_image_version}.tar.gz sn-stack/\",\n",
    "    f\"curl -s -k -u {nginx_user}:{nginx_password} -T esnet-smartnic-fw-{docker_image_version}.tar.gz https://{storage_vm_ip}/ejfat-data/smartnic-docker-images/\",\n",
    "    f\"cd esnet-smartnic-fw; curl -s -k -u {nginx_user}:{nginx_password} -T sn-stack-{docker_image_version}.tar.gz https://{storage_vm_ip}/ejfat-data/smartnic-docker-images/\"\n",
    "]\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43debbbc-f076-4efc-96c5-30a08a82dffb",
   "metadata": {},
   "source": [
    "## Download containers from storage VM and install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3029f0af-034a-4a7c-af0c-8e459fbe3505",
   "metadata": {},
   "source": [
    "You can use previously built containers here by downloading them from the storage VM and installing into Docker.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b16e6b0-12c5-4479-8332-29de259b77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker image prefixes\n",
    "docker_image_prefixes = ['smartnic-dpdk-docker', 'xilinx-labtools-docker', 'esnet-smartnic-fw']\n",
    "\n",
    "# download and install all available docker images with the right version\n",
    "commands = []\n",
    "\n",
    "# we add sn-stack here - it's not a docker image, but just a zipped up tree\n",
    "# we need to download it, but it doesn't get installed as a docker image\n",
    "for prefix in docker_image_prefixes + ['sn-stack']:\n",
    "    commands.append(f\"curl -s -k -u {nginx_user}:{nginx_password} http://{storage_vm_ip}/ejfat-data/smartnic-docker-images/{prefix}-{docker_image_version}.tar.gz > {prefix}-{docker_image_version}.tar.gz\")\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58870a61-76f9-4b82-8929-0b8cc4bb2bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the images in the docker on the node. \n",
    "# Remember to checkout esnet-smartnic-fw repo (no need to build, just check it out)\n",
    "commands = [ f\"if [ ! -e esnet-smartnic-fw ]; then git clone https://github.com/esnet/esnet-smartnic-fw.git; fi\" ]\n",
    "for prefix in docker_image_prefixes:\n",
    "    commands.append(f\"docker load --input {prefix}-{docker_image_version}.tar.gz\")\n",
    "\n",
    "commands.append(f\"docker image ls\")\n",
    "\n",
    "# untar sn-stack into the previously checked out repo\n",
    "commands.append(f\"tar -zxf sn-stack-{docker_image_version}.tar.gz -C esnet-smartnic-fw/\")\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b9f52e-27aa-4975-aec6-43e8b2f293cf",
   "metadata": {},
   "source": [
    "## Generate secrets\n",
    "\n",
    "Secret tokens are in use both between control plane and FPGA as well as clients and the control plane. We generate them here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574be605-6bdd-4eda-b0d8-30b511a85139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import secrets\n",
    "import string\n",
    "\n",
    "def generate_token(length=32):\n",
    "    return ''.join(secrets.choice(string.ascii_uppercase + string.digits)\n",
    "              for i in range(length))\n",
    "\n",
    "sn_cfg_token = generate_token()\n",
    "sn_p4_token = generate_token()\n",
    "cp_admin_token = generate_token()\n",
    "\n",
    "print(f'Generated the following tokens: \\n\\tsn_cfg={sn_cfg_token}\\n\\tsn_p4={sn_p4_token}\\n\\tcp_admin={cp_admin_token}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04836774-8d98-4aaa-a2cb-350bedd3d247",
   "metadata": {},
   "source": [
    "## Stand up the stack\n",
    "\n",
    "Here we bring up the FPGA and UDPLBd on top of it for control plane following these instructions: \n",
    "- https://github.com/esnet/esnet-smartnic-fw/blob/main/sn-stack/README.INSTALL.md "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28b6a3-19cf-4c29-b267-5c0e4c7a2fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure sn-stack/.env\n",
    "# You can use `openssl rand -base64 24` to generate tokens\n",
    "env_file = f\"\"\"\n",
    "# block-start Added by the FABRIC notebook \n",
    "# relies on default already having SN_INGRESS_PORT=8440\n",
    "FPGA_PCIE_DEV=0000:1f:00\n",
    "# enables traefik\n",
    "COMPOSE_PROFILES=smartnic-mgr-vfio-unlock,smartnic-ingress\n",
    "SN_HOST=localhost\n",
    "SN_CFG_AUTH_TOKEN={sn_cfg_token}\n",
    "SN_P4_AUTH_TOKEN={sn_p4_token}\n",
    "SMARTNIC_DPDK_IMAGE_URI=smartnic-dpdk-docker:ubuntu-dev\n",
    "LABTOOLS_IMAGE_URI=xilinx-labtools-docker:ubuntu-dev\n",
    "SMARTNIC_FW_IMAGE_URI=esnet-smartnic-fw:ubuntu-dev\n",
    "# block-end \n",
    "\"\"\"\n",
    "\n",
    "# upload the sn-cfg setup file to be executed from inside the container once it is up\n",
    "sn_cfg_file=\"config/u280_setup.sh\"\n",
    "# scratch is mounted into the container\n",
    "sn_cfg_install_path=\"/home/ubuntu/esnet-smartnic-fw/sn-stack/scratch/u280_setup.sh\"\n",
    "result = node.upload_file(sn_cfg_file, sn_cfg_install_path)\n",
    "\n",
    "commands = [\n",
    "    f\"echo '{env_file}' >> ~/esnet-smartnic-fw/sn-stack/.env\",\n",
    "    f\"chmod a+x {sn_cfg_install_path}\"\n",
    "]\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080cf482-b71a-485e-a41f-3eedfe4668a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring up the stack\n",
    "\n",
    "commands = [\n",
    "#    \"cd esnet-smartnic-fw/sn-stack; mv traefik/config.d/certs.yml{,.hidden}; docker compose up -d\"\n",
    "    \"cd esnet-smartnic-fw/sn-stack; docker compose up -d\"\n",
    "]\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5cd829-624d-4699-bfab-bad553f3c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for some time, check the logs\n",
    "commands = [\n",
    "    f\"cd esnet-smartnic-fw/sn-stack; docker compose logs smartnic-hw\"\n",
    "]\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b980e1-23d1-444f-b0b5-1db481b9f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run initial configuration\n",
    "# the command should print out details about the detected card something like \n",
    "# ----------------------------------------\n",
    "# Device ID: 0\n",
    "# ----------------------------------------\n",
    "# PCI:\n",
    "#     Bus ID:    0000:1f:00.0\n",
    "#     Vendor ID: 0x10ee\n",
    "#     Device ID: 0x903f\n",
    "# Build:\n",
    "#     Number: 0x0000e154\n",
    "#     Status: 0x09231435\n",
    "#     DNA[0]: 0x4cc061c5\n",
    "#     DNA[1]: 0x016ad0a3\n",
    "#     DNA[2]: 0x40020000\n",
    "# Card:\n",
    "#     Name:                  ALVEO U280 PQ\n",
    "#     Profile:               U280\n",
    "#     Serial Number:         21770329D004\n",
    "#     Revision:              1.0\n",
    "#     SC Version:            4.0\n",
    "#     Config Mode:           MASTER_SPI_X4\n",
    "#     Fan Presence:          P\n",
    "#     Total Power Available: 225W\n",
    "#     Cage Types:\n",
    "#     MAC Addresses:\n",
    "#         0: 00:0A:35:0E:26:36\n",
    "#         1: 00:0A:35:0E:26:37\n",
    "#         2: FF:FF:FF:FF:FF:FF\n",
    "#         3: FF:FF:FF:FF:FF:FF\n",
    "# Critically it should show 'Link: up' at the bottom for both ports\n",
    "#\n",
    "commands = [\n",
    "    f\"cd esnet-smartnic-fw/sn-stack; docker compose exec smartnic-fw /scratch/u280_setup.sh\"\n",
    "]\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d388bbc5-c886-4686-93b2-9609a74fbedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring the stack down\n",
    "commands = [\n",
    "    f\"cd esnet-smartnic-fw/sn-stack;docker compose down -v --remove-orphans\"\n",
    "]\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ad132e-b269-4e31-8a20-79ac3f03c499",
   "metadata": {},
   "source": [
    "## Stand up UDPLBd Control Plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b591d2-47c2-4e1b-b237-9b755d7f9aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a config file based on issued IP addresses\n",
    "\n",
    "# we need several inputs to this file:\n",
    "# - secret tokens (to talk to FPGA and to clients)\n",
    "# - list of IPv4 addresses to use (we provide fake IPv6 addresses for now)\n",
    "# - IPv4 address to use for CP and Sync (usually the same)\n",
    "# - list of UDP ports for sync messages\n",
    "# - path to TLS cert\n",
    "\n",
    "# we need to use ssh keys here because UDPLBd repo is private\n",
    "# overwrite with location of your github key\n",
    "github_key = '/home/fabric/work/fabric_config/github_ecdsa'\n",
    "vm_key_location = f'/home/ubuntu/.ssh/github_ecdsa'\n",
    "\n",
    "# which branch of UDPLBd code\n",
    "udplbd_branch = \"main\"\n",
    "\n",
    "# other parameter inputs\n",
    "cp_ipv4 = storage_nic_ip\n",
    "cp_listen_port = 18008\n",
    "start_sync_port = 19010\n",
    "sn_listen_port = 8440\n",
    "\n",
    "# generate lists inserted into config\n",
    "ipv4_list = \"    - \" + \"\\n    - \".join(map(str, fpga_ips))\n",
    "udp_port_list = \"    - \" + \"\\n    - \".join(map(str, range(start_sync_port, start_sync_port + fpga_ips_qty)))\n",
    "\n",
    "# config file template\n",
    "cp_config_file = f\"\"\"\n",
    "lb:\n",
    "  id: 0\n",
    "  ipv4:\n",
    "{ipv4_list}\n",
    "  ipv6:\n",
    "    - \"2001:400:a300::10\"\n",
    "    - \"2001:400:a300::11\"\n",
    "    - \"2001:400:a300::12\"\n",
    "    - \"2001:400:a300::13\"\n",
    "    - \"2001:400:a300::14\"\n",
    "    - \"2001:400:a300::15\"\n",
    "    - \"2001:400:a300::16\"\n",
    "    - \"2001:400:a300::17\"\n",
    "  mac_unicast: \"02:aa:bb:cc:dd:08\"\n",
    "  mac_broadcast: \"33:33:ff:00:00:08\"\n",
    "  allow_private: true\n",
    "event_numbers:\n",
    "  host: {cp_ipv4}\n",
    "  ports:\n",
    "{udp_port_list}\n",
    "controller:\n",
    "  duration: 1s\n",
    "  offset: 800ms\n",
    "database:\n",
    "  file: \"/tmp/udplbd.db\"\n",
    "  collection:\n",
    "    enable: true\n",
    "    interval: \"100ms\"\n",
    "    retention: \"168h\"\n",
    "server:\n",
    "  listen:\n",
    "    - '{cp_ipv4}:{cp_listen_port}'\n",
    "  auth_token: \"{cp_admin_token}\"\n",
    "  tls:\n",
    "    enable: true\n",
    "    certFile: \"/etc/udplbd/server_cert.pem\"\n",
    "    keyFile: \"/etc/udplbd/server_key.pem\"\n",
    "http:\n",
    "  listen: 127.0.0.1:8080\n",
    "  dir: /frontend\n",
    "log:\n",
    "  level: debug\n",
    "smartnic:\n",
    "  - host: \"localhost\"\n",
    "    port: {sn_listen_port}\n",
    "    mock: false\n",
    "    auth_token: \"{sn_p4_token}\"\n",
    "    tls:\n",
    "      enable: true\n",
    "      verify: false\n",
    "prometheus:\n",
    "  enable: true\n",
    "  listen: 127.0.0.1:2108\n",
    "mockclient:\n",
    "  status_update_interval_ms: 1000\n",
    "  status_update_to_p4_update_latency_ms: 500\n",
    "  buffer_slope_per_second: 100\n",
    "  buf_count: 1000\n",
    "  set_point_percent: 0.5\n",
    "\"\"\"\n",
    "\n",
    "# upload the GitHub SSH key onto the VM\n",
    "result = node.upload_file(github_key, vm_key_location)\n",
    "\n",
    "# clone the UDPLBd repo\n",
    "# change permissions on imported key\n",
    "# generate a private key and cert\n",
    "# install config file where needed\n",
    "commands = [\n",
    "    f\"rm -rf udplbd/\",\n",
    "    f\"chmod go-rwx {vm_key_location}\",\n",
    "    f\"GIT_SSH_COMMAND='ssh -i {vm_key_location} -o IdentitiesOnly=yes -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no' git clone -b {udplbd_branch} git@github.com:esnet/udplbd.git\",\n",
    "    f'openssl req -x509 -newkey rsa:4096 -keyout udplbd/etc/server_key.pem -out udplbd/etc/server_cert.pem -sha256 -days 365 -nodes -subj \"/CN=cpnode/subjectAltName=IP:{cp_ipv4}\" -nodes',\n",
    "    f'echo \"{cp_config_file}\" > ./udplbd/etc/config.yml'\n",
    "]\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fe9995-be77-4d3d-9bd4-bd5d13501211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the stack\n",
    "commands = [\n",
    "    f'cd udplbd; docker compose up -d'\n",
    "]\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde29025-714e-4490-9530-66f1f01eeb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the logs\n",
    "commands = [\n",
    "    'docker compose ls',\n",
    "    'cd udplbd; docker compose logs'\n",
    "]\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528fca1c-4073-4ee1-97bf-d906bad99cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need to restart it, this is the stop part\n",
    "commands = [\n",
    "    'cd udplbd; docker compose stop; docker compose rm -f; docker image rm udplbd'\n",
    "]\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8324e46-b3ec-4610-903e-d064bc3ef411",
   "metadata": {},
   "source": [
    "## Run some tests to make sure things are up\n",
    "- Run lbadm from a container to do commands like 'version' and 'overview'\n",
    "- Run lbadm from a container to reserve an instance, make sure it succeeds and that we can ping the IP of the instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd332a48-6a45-460e-af23-e585437531fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run version\n",
    "commands = [\n",
    "    f'docker run ibaldin/e2sar:latest lbadm --version -u \"ejfats://{cp_admin_token}@{cp_ipv4}:{cp_listen_port}/\" -v'\n",
    "]\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbba02d-6f68-426a-aac8-6bfaa0c9a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run overview (unlikely to show anything)\n",
    "commands = [\n",
    "    f'docker run ibaldin/e2sar:latest lbadm --overview -u \"ejfats://{cp_admin_token}@{cp_ipv4}:{cp_listen_port}/\" -v'\n",
    "]\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d1a42-61bd-40bd-8c05-ef5f8bed605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserve an LB, observe the returned URI with 'data=' IPv4 address of the allocated LB, attempt to ping it\n",
    "lbname = 'mylb'\n",
    "duration = '02:00:00'\n",
    "commands = [\n",
    "    f'docker run ibaldin/e2sar:latest lbadm --reserve -u \"ejfats://{cp_admin_token}@{cp_ipv4}:{cp_listen_port}/\" -v -l {lbname} -d \"{duration}\" -a 192.168.1.1 -e'\n",
    "]\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499d713a-2520-4878-b18d-c6fb976b70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ping the data IP address returned in EJFAT_URI\n",
    "lb_address = \"10.138.1.253\"\n",
    "ping_from = cp_ipv4\n",
    "\n",
    "commands = [\n",
    "    f\"sudo ping -q -f -I {ping_from} -c 100 {lb_address}\"\n",
    "]\n",
    "\n",
    "execute_commands(node, commands)\n",
    "print('Observe 0% packet loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa35aafc-83d5-4c49-84e4-342eb37bacee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free the load balancer - we are good to go\n",
    "# COPY INSTANCE TOKEN FROM THE OUTPUT OF RESERVE COMMAND ABOVE\n",
    "instance_token = 'ejfats://<replaceme>'\n",
    "commands = [\n",
    "    f'docker run ibaldin/e2sar:latest lbadm --free -u \"{instance_token}\" -v -l {lbname} -d \"{duration}\" -a 192.168.1.1 -e'\n",
    "]\n",
    "\n",
    "execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10cb73a-6f70-4a6b-a5cf-f832a130421d",
   "metadata": {},
   "source": [
    "## Extend the slice (as needed)\n",
    "\n",
    "If you need to extend the storage slice, you can just execute the following two cells. They display the slice expiration date and optionally extend by 2 weeeks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e53d4-fe20-449b-a61c-061e3eb967bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=slice_name)\n",
    "a = slice.show()\n",
    "nets = slice.list_networks()\n",
    "nodes = slice.list_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122cdde3-5f47-41fc-bd07-0ff75d0a415c",
   "metadata": {},
   "source": [
    "Renew the slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a090a0-bb22-4425-832c-52921d463a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from datetime import timedelta\n",
    "\n",
    "# Set end host to now plus 14 days\n",
    "end_date = (datetime.now(timezone.utc) + timedelta(days=14)).strftime(\"%Y-%m-%d %H:%M:%S %z\")\n",
    "\n",
    "try:\n",
    "    slice = fablib.get_slice(name=slice_name)\n",
    "\n",
    "    slice.renew(end_date)\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833ba11-262c-4700-b8e6-5fb419345718",
   "metadata": {},
   "source": [
    "## Delete the Slice (as needed)\n",
    "\n",
    "Please delete your slice when you are done with your experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a946d9a-1a4a-426b-9df0-64ebd4afa18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=slice_name)\n",
    "slice.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d789f3-151d-421e-8e3e-84ed3e16ec6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
