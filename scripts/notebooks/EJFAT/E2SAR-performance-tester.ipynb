{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b8f888-5788-4dfe-ad0a-cb5b0e567188",
   "metadata": {},
   "source": [
    "# EJFAT Performance Tester\n",
    "\n",
    "This notebook stands up a slice of 2 nodes - sender, receiver. E2SAR code is deployed on `sender` and `receiver` nodes for testing. The slice uses dedicated Mellanox ConnectX 6 NICs and is created within a single FABRIC site for simplicity. It uses a single L2 bridge connection between one port on each of the NICs with RFC1918 IPv4 addressing, allowing nodes to talk to each other. The notebook pins vCPUs and RAM of the VM to the NUMA domain of the NIC to provide a reproducible environment for experiments.\n",
    "\n",
    "Slice example:\n",
    "\n",
    "<div>\n",
    "    <img src=\"figs/UDP LB Control Plane Testing slice.png\" width=500>\n",
    "</div>\n",
    "\n",
    "## Preparation and overview\n",
    "\n",
    "- Be sure to [generate a keypair for Jupyter Hub](GitHubSSH.ipynb) and register it with GitHub - the keys will be used to check out the code from private repositories, like [UDPLBd](https://github.com/esnet/udplbd) and [E2SAR](https://github.com/JeffersonLab/E2SAR).\n",
    "- Note that for E2SAR development and testing sender and receiver node compile/build environments will be setup via post-boot scripts ([sender](post-boot/sender.sh) and [receiver](post-boot/recver.sh)) and grpc++/boost is installed as a debian package from [Github releases](https://github.com/JeffersonLab/E2SAR/releases) with static and dynamic libraries compiled for ubuntu22\n",
    "- This does not setup the control plane node for anything, but testing a specific version - you can set which branch of UDPLBd to check out and a containerized version is built and stood up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0bb3e-52ed-48c7-98ae-b51e62af39e4",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "This cell must be executed whether you are creating a new slice or continuing work on the old one. If you are continuing work, you then skip the slice create section and proceed to wherever you left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a3378-dd68-4685-b0d2-4cae8ad462b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# EDIT THIS\n",
    "#\n",
    "\n",
    "# GitHub SSH key file (private) registered using the GitHubSSH.ipynb notebook referenced above\n",
    "github_key = '/home/fabric/work/fabric_config/github_ecdsa'\n",
    "\n",
    "# branches for E2SAR that we want checked out on the VMs\n",
    "e2sar_branch = 'v0.2.0'\n",
    "\n",
    "# base distro 'ubuntu' or 'rocky'\n",
    "distro_name = 'ubuntu'\n",
    "\n",
    "#base distro version, currently only for ubuntu 20,22,24. E2SAR dependencies will be \n",
    "#downloaded for the appropriate versions.\n",
    "distro_version = '22'\n",
    "\n",
    "# note that the below is distribution specific ('ubuntu' for ubuntu and so on)\n",
    "home_location = {\n",
    "    'ubuntu': '/home/ubuntu',\n",
    "    'rocky' : '/home/rocky'\n",
    "}[distro_name]\n",
    "\n",
    "vm_key_location = f'{home_location}/.ssh/github_ecdsa'\n",
    "\n",
    "# which test suites in E2SAR to run (leave empty to run all)\n",
    "# you can set 'unit' or 'live' to run unit or live tests only\n",
    "e2sar_test_suite = ''\n",
    "\n",
    "# name of the network connecting the nodes\n",
    "net_name = 'site_bridge_net'\n",
    "\n",
    "# url of e2sar deps. Find the appropriate version for the OS at https://github.com/JeffersonLab/E2SAR/releases\n",
    "static_release_url = 'https://github.com/JeffersonLab/E2SAR/releases/download/' # don't need to change this\n",
    "e2sar_dep_artifcat = 'e2sar-deps_0.1.5_amd64.deb'\n",
    "e2sar_release_ver = 'E2SAR-main-0.1.5'\n",
    "e2sar_dep_url = static_release_url + e2sar_release_ver + \"-\" + distro_name + \"-\" + distro_version + \".04/\" + e2sar_dep_artifcat\n",
    "\n",
    "#\n",
    "# SHOULDN'T NEED TO EDIT BELOW\n",
    "#\n",
    "# Preamble\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from datetime import timedelta\n",
    "\n",
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "\n",
    "from ipaddress import ip_address, IPv4Address, IPv6Address, IPv4Network, IPv6Network\n",
    "import ipaddress\n",
    "\n",
    "import json\n",
    "\n",
    "fablib = fablib_manager()             \n",
    "fablib.show_config();\n",
    "\n",
    "# Using docker image for cpnode by default\n",
    "distro_image = 'default_' + distro_name + '_' + distro_version\n",
    "\n",
    "# variable settings\n",
    "slice_name = f'E2SAR Performance Testing with e2sar[{e2sar_branch}] on {distro_name}'\n",
    "\n",
    "# for each node specify IP address (assuming /24), OS image\n",
    "# note that most of the keys in these dictionaries map directly\n",
    "# onto parameters to add_node()\n",
    "\n",
    "ram = 8\n",
    "cores = 4\n",
    "disk = 100\n",
    "\n",
    "node_config = {\n",
    "    'sender': {\n",
    "        'ip':'192.168.0.1', \n",
    "        'image': distro_image,\n",
    "        'cores': cores,\n",
    "        'ram': ram,\n",
    "        'disk': disk },\n",
    "    'recver': {\n",
    "        'ip':'192.168.0.2', \n",
    "        'image':distro_image,\n",
    "        'cores':cores,\n",
    "        'ram': ram,\n",
    "        'disk': disk },\n",
    "}\n",
    "# skip these keys as they are not part of add_node params\n",
    "skip_keys = ['ip']\n",
    "# this is the NIC to use\n",
    "nic_model = 'NIC_ConnectX_6'\n",
    "# the subnet should match IPs\n",
    "subnet_str = \"192.168.0.0/24\" \n",
    "subnet = IPv4Network(subnet_str)\n",
    "\n",
    "def execute_single_node(node, commands):\n",
    "    for command in commands:\n",
    "        print(f'\\tExecuting \"{command}\" on node {node.get_name()}')\n",
    "        #stdout, stderr = node.execute(command, quiet=True, output_file=node.get_name() + '_install.log')\n",
    "        stdout, stderr = node.execute(command)\n",
    "    if not stderr and len(stderr) > 0:\n",
    "        print(f'Error encountered with \"{command}\": {stderr}')\n",
    "        \n",
    "def execute_commands(node, commands):\n",
    "    if isinstance(node, list):\n",
    "        for n in node:\n",
    "            execute_single_node(n, commands)\n",
    "    else:\n",
    "        execute_single_node(node, commands)\n",
    "\n",
    "# until fablib fixes this\n",
    "def get_management_os_interface(node) -> str or None:\n",
    "        \"\"\"\n",
    "        Gets the name of the management interface used by the node's\n",
    "        operating system. \n",
    "\n",
    "        :return: interface name\n",
    "        :rtype: String\n",
    "        \"\"\"\n",
    "        stdout, stderr = node.execute(\"sudo ip -j route list\", quiet=True)\n",
    "        stdout_json = json.loads(stdout)\n",
    "\n",
    "        for i in stdout_json:\n",
    "            if i[\"dst\"] == \"default\":\n",
    "                return i[\"dev\"]\n",
    "\n",
    "        stdout, stderr = node.execute(\"sudo ip -6 -j route list\", quiet=True)\n",
    "        stdout_json = json.loads(stdout)\n",
    "\n",
    "        for i in stdout_json:\n",
    "            if i[\"dst\"] == \"default\":\n",
    "                return i[\"dev\"]\n",
    "\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b813d-21d5-4b18-a3f7-fd0f9f4d42c8",
   "metadata": {},
   "source": [
    "## Create the slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dbf90d-5990-4453-9ae9-3def21b5910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all slices I have running\n",
    "output_dataframe = fablib.list_slices(output='pandas')\n",
    "if output_dataframe:\n",
    "    print(output_dataframe)\n",
    "else:\n",
    "    print('No active slices under this project')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a6afb-78de-4251-81ba-d65cac091028",
   "metadata": {},
   "source": [
    "If your slice is already active you can skip to the 'Get Slice Details' section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160f239-a64a-47d4-9c34-5fe9a0e3fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which sites have available FPGAs on hosts (and also list memory, disk and core on those hosts)\n",
    "# Overall list of sites that are usable with ESnet workflow\n",
    "sites_to_check = ['STAR', 'TACC', 'MICH', 'UTAH', 'NCSA', 'WASH', 'DALL', 'SALT', 'UCSD', 'CLEM', 'LOSA', 'KANS', 'PRIN', 'SRI']\n",
    "\n",
    "# worker name is <site in lower case>-w[0-9]+.fabric.net\n",
    "hosts = fablib.list_hosts(fields=['name','cores_available','ram_available','disk_available','nic_connectx_6_available'], \n",
    "                          filter_function=lambda s: (s['name'].split('-')[0].upper() in sites_to_check) and \n",
    "                          s['nic_connectx_6_available']==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54daa96-a679-4419-b570-f6e3eaeb26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend a site with availability picking one with the highest RAM\n",
    "\n",
    "# hosts is a Styler over a DataFrame, we want to get the underlying numpy array\n",
    "recommended_sites = []\n",
    "for host in hosts.data.to_numpy():\n",
    "    if host[1] > 2*cores and host[2] > 2*ram and host[3] > 2*disk and host[4] == 2:\n",
    "        # each entry is [SITE, cores, ram, disk]\n",
    "        recommended_sites.append([host[0].split('-')[0].upper(), host[1], host[2], host[3]])\n",
    "\n",
    "# sort recommended sites by the amount of RAM and get the highest RAM\n",
    "if len(recommended_sites) > 0:\n",
    "    selected_site = sorted(recommended_sites, key=lambda entry: entry[2])[-1][0]\n",
    "    print(f'Recommended site is {selected_site}')\n",
    "else:\n",
    "    print(f'Unable to find a usable site among {sites_to_check}')\n",
    "\n",
    "# write selected site into node attributes\n",
    "for n in node_config:\n",
    "    node_config[n]['site'] = selected_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b7969-df0d-4c8e-b909-acc30dc8c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a slice\n",
    "slice = fablib.new_slice(name=slice_name)\n",
    "\n",
    "# create a network\n",
    "net1 = slice.add_l2network(name=net_name, subnet=subnet)\n",
    "\n",
    "nodes = dict()\n",
    "# create  nodes for sending and receiving with a selected network card\n",
    "# use subnet address assignment\n",
    "for node_name, node_attribs in node_config.items():\n",
    "    print(f\"{node_name=} {node_attribs['ip']}\")\n",
    "    nodes[node_name] = slice.add_node(name=node_name, **{x: node_attribs[x] for x in node_attribs if x not in skip_keys})\n",
    "    nic_interface = nodes[node_name].add_component(model=nic_model, name='_'.join([node_name, nic_model, 'nic'])).get_interfaces()[0]\n",
    "    net1.add_interface(nic_interface)\n",
    "    nic_interface.set_mode('config')\n",
    "    nic_interface.set_ip_addr(node_attribs['ip'])\n",
    "    # postboot configuration is under 'post-boot' directory\n",
    "    nodes[node_name].add_post_boot_upload_directory('post-boot','.')\n",
    "    nodes[node_name].add_post_boot_execute(f'chmod +x post-boot/{node_name}.sh && ./post-boot/{node_name}.sh')\n",
    "\n",
    "print(f'Creating a {distro_name} based slice named \"{slice_name}\" with nodes in {selected_site}')\n",
    "\n",
    "# Submit the slice\n",
    "slice.submit();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0ef1ea-11b0-4eeb-9ca7-a4a6fba7fb4c",
   "metadata": {},
   "source": [
    "## Get Slice Details\n",
    "\n",
    "If not creating a new slice, and just continuing work on an existing one, execute this cell (in addition to the preamble) and then any of the cells below will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c4bf4-f5e6-42d8-9994-b513e9762d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get slice details (if not creating new)\n",
    "slice = fablib.get_slice(name=slice_name)\n",
    "a = slice.show()\n",
    "nets = slice.list_networks()\n",
    "nodes = slice.list_nodes()\n",
    "\n",
    "sender = slice.get_node(name=\"sender\")\n",
    "recver = slice.get_node(name=\"recver\")\n",
    "\n",
    "# get node dataplane addresses\n",
    "sender_addr = sender.get_interface(network_name=net_name).get_ip_addr()\n",
    "recver_addr = recver.get_interface(network_name=net_name).get_ip_addr()\n",
    "\n",
    "sender_iface = sender.get_interface(network_name=net_name)\n",
    "recver_iface = recver.get_interface(network_name=net_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b9f66-61de-40dd-a14e-efd726562811",
   "metadata": {},
   "source": [
    "# Performance Tuning\n",
    "\n",
    "Here we make sure to\n",
    "1. Pin the vCPUs to physical CPUs that are in the NUMA node of the NIC\n",
    "2. Pin the RAM the VM is using to the same NUMA node\n",
    "3. Set up socket buffers, MTU and firewall to maximize the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ed4ae-fb21-45f4-8994-9c28089fea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(slice_name)\n",
    "\n",
    "for node in slice.get_nodes():\n",
    "    nic_name = '_'.join([node.get_name(), nic_model, 'nic'])\n",
    "    \n",
    "    # Pin all vCPUs for VM to same Numa node as the component\n",
    "    node.pin_cpu(component_name=nic_name)\n",
    "    \n",
    "    # User can also pass in the range of the vCPUs to be pinned \n",
    "    #node.pin_cpu(component_name=nic_name, cpu_range_to_pin=\"0-3\")\n",
    "    \n",
    "    # Pin memmory for VM to same Numa node as the components\n",
    "    node.numa_tune()\n",
    "    \n",
    "    # Reboot the VM\n",
    "    node.os_reboot()\n",
    "\n",
    "# wait for reboot to complete\n",
    "slice.wait_ssh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a06af0-3710-49cb-8962-13ebd8114431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover network configuration after reboot\n",
    "\n",
    "for n in slice.get_nodes():  \n",
    "    n.config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d549025-93b5-4148-8da9-5251d7566945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set system-wide send and receive socket buffer limits to 512MB. e2sar_perf then will set SO_RCVBUF and SO_SNDBUF options on sending and receiving sockets\n",
    "# this is system specific, so we don't do it through a file, but on command line. Normally this goes into /etc/sysctl.conf or /etc/sysctl.d/90-local.conf \n",
    "# or similar\n",
    "commands = [\n",
    "    f\"sudo sysctl net.core.rmem_max=536870912\",\n",
    "    f\"sudo sysctl net.core.wmem_max=536870912\",\n",
    "    f\"sysctl net.core.wmem_max net.core.rmem_max\"\n",
    "]\n",
    "execute_commands([sender, recver], commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61de736-44c5-4adf-9c24-c6875ed7a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note  that in this slice we are guaranteed to have path MTU to be at least 9k, because FABRIC\n",
    "# switches are configured for jumbo frames. In real life you need to consult your network administrator\n",
    "# as simply setting MTU on sender and receiver may be insufficient.\n",
    "mtu = '9000'\n",
    "sender.execute(f\"sudo ip link set dev {sender_iface.get_os_interface()} mtu {mtu}\")\n",
    "recver.execute(f\"sudo ip link set dev {recver_iface.get_os_interface()} mtu {mtu}\")\n",
    "\n",
    "# test with no-defragment (DF=1) ping packets that path indeed supports MTU of 9000 \n",
    "# (ping  packet  of 8972 payload length)\n",
    "# send 10 packets and expect all of them to make it\n",
    "stdout, stderr = sender.execute(f\"sudo ping -f -s 8972 -c 10 -M do {recver_addr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725b9489-2ddb-4f94-b761-6e2eafc7f876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to setup the firewall to allow traffic to pass to the receiver\n",
    "\n",
    "mgmt_iface_name = get_management_os_interface(recver)\n",
    "data_iface = recver.get_interface(network_name=net_name)\n",
    "data_iface_name = data_iface.get_os_interface()\n",
    "\n",
    "print(f'Adding {mgmt_iface_name} and lo and data interface to trusted zone')\n",
    "commands = [\n",
    "    f'sudo firewall-cmd --permanent --zone=trusted --add-interface={data_iface_name}',\n",
    "    f'sudo firewall-cmd --permanent --zone=trusted --add-interface=lo',\n",
    "    f'sudo firewall-cmd --permanent --zone=trusted --add-interface={mgmt_iface_name}',\n",
    "    f'for i in $(sudo firewall-cmd --zone=public --list-services); do sudo firewall-cmd --zone=public --permanent --remove-service=$i; done',\n",
    "]\n",
    "commands.append(f'sudo firewall-cmd --reload')\n",
    "commands.append(f'sudo firewall-cmd --list-all --zone=public')\n",
    "\n",
    "execute_commands([recver], commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c5e64-2a8c-443c-9f80-884b053ad6bf",
   "metadata": {},
   "source": [
    "## Clone E2SAR code into sender and receiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd9b8f-87b6-4150-b03a-81902b8fd9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install github ssh key and set up build environment variables for interactive logins\n",
    "commands = [\n",
    "    f\"chmod go-rwx {vm_key_location}\",\n",
    "    # Meson won't detect boost by merely setting cmake_prefix_path, instead set BOOST_ROOT env variable \n",
    "    # for gRPC it is enough to set -Dpkg_config_path option to meson\n",
    "    f\"echo 'export BOOST_ROOT=/usr/local/ LD_LIBRARY_PATH=/usr/local/lib' >> ~/.profile\",\n",
    "    f\"echo 'export BOOST_ROOT=/usr/local/ LD_LIBRARY_PATH=/usr/local/lib' >> ~/.bashrc\",\n",
    "]\n",
    "\n",
    "for node in [sender, recver]:    \n",
    "    # upload the GitHub SSH key onto the VM\n",
    "    result = node.upload_file(github_key, vm_key_location)\n",
    "    execute_commands(node, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e529e2-ec01-451f-91a3-52b1462a496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download boost and grpc dependencies from releases\n",
    "commands = [\n",
    "    f\"wget -q -O boost_grpc.deb {e2sar_dep_url}\",\n",
    "    f\"sudo apt -yq install ./boost_grpc.deb\",\n",
    "]\n",
    " \n",
    "execute_commands([sender, recver], commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf2d4e-7602-4cdd-ba55-b7abfe0b5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout E2SAR (including the right branch) using that key, install grpc and boost binary that is stored in the repo\n",
    "commands = [\n",
    "    f\"GIT_SSH_COMMAND='ssh -i {vm_key_location} -o IdentitiesOnly=yes -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no' git clone --recurse-submodules --depth 1 -b {e2sar_branch} git@github.com:JeffersonLab/E2SAR.git\",\n",
    "    #f\"cd E2SAR; GIT_SSH_COMMAND='ssh -i {vm_key_location} -o IdentitiesOnly=yes -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no' git submodule init\",\n",
    "]\n",
    " \n",
    "execute_commands([sender, recver], commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b93d76-1c92-4065-bced-b250420b1381",
   "metadata": {},
   "source": [
    "## Building, Running Unit and Live Tests\n",
    "\n",
    "On RedHat/Rocky derivatives the build fails. Likely has to do with the outdated gcc/g++ and stdlib. E2SAR/build/ninja.build must be modified - all mentions of `-std=c++11` must be removed from it.\n",
    "\n",
    "To avoid this after the build step (and the next one after) the below command invokes `sed` to remove mentions of `c++11` from build.ninja file. This is a hack, don't just walk away, **RUN**!\n",
    "\n",
    "Also note that the install directory is set to `$(HOME)/e2sar-install`. So if you run `meson install -C build` this is where the code will end up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277f2950-0237-4638-929c-2ffa8d12b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to test liburing and/or libnuma, install it here \n",
    "# (we are deliberately not adding this to the postboot script)\n",
    "commands = [\n",
    "    \"sudo apt-get install -y liburing-dev libnuma-dev\"\n",
    "]\n",
    "execute_commands([sender, recver], commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca833f03-3c6f-4899-a744-e66adb2d1ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also install and enable perf tools if needed. Last command does a simple test.\n",
    "commands = [\n",
    "    \"sudo apt-get install -y linux-tools-common linux-tools-generic\",\n",
    "    \"echo -1 | sudo tee /proc/sys/kernel/perf_event_paranoid\",\n",
    "    \"echo 0 | sudo tee /proc/sys/kernel/kptr_restrict\",\n",
    "    \"perf stat ls\"\n",
    "]\n",
    "execute_commands([sender, recver], commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c46214-d05f-47a5-94d0-031cc6ecbec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the code, compile and test\n",
    "# note that most live tests only need the simplest URI - ejfats://token@ip:port/\n",
    "# however the e2sar_reas_live_test requires data and sync addresses, and data address must\n",
    "# be real (so we use loopback). Hence the long form of the URI for live tests \n",
    "# (other tests simply ignore the parts of the URI they don't need.)\n",
    "\n",
    "commands = [\n",
    "    f\"cd E2SAR; PATH=$HOME/.local/bin:/usr/local/bin:$PATH BOOST_ROOT=/usr/local/ LD_LIBRARY_PATH=/usr/local/lib/ meson setup -Dpkg_config_path=/usr/local/lib/pkgconfig/:/usr/lib/lib64/pkgconfig/ --prefix {home_location}/e2sar-install build && sed -i 's/-std=c++11//g' build/build.ninja\",\n",
    "    f\"cd E2SAR/build; PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/  meson compile -j 2\",\n",
    "]\n",
    " \n",
    "execute_commands([sender, recver], commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e3cc8b-cc92-4d2e-9f58-5c3b63813a8f",
   "metadata": {},
   "source": [
    "If you want to update the code and rebuild, run the cell below. Again, making sure we update ninja.build... Look away..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c490a3f1-a418-4fad-b3bc-8d02b67c9912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the code, compile and test\n",
    "# note that most live tests only need the simplest URI - ejfats://token@ip:port/\n",
    "# however the e2sar_reas_live_test requires data and sync addresses, and data address must\n",
    "# be real (so we use loopback). Hence the long form of the URI for live tests \n",
    "# (other tests simply ignore the parts of the URI they don't need.)\n",
    "\n",
    "commands = [\n",
    "    f\"cd E2SAR; GIT_SSH_COMMAND='ssh -i {vm_key_location} -o IdentitiesOnly=yes -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no' git pull origin {e2sar_branch}\",\n",
    "    f\"cd E2SAR; BOOST_ROOT=/usr/local/ PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/ meson setup -Dpkg_config_path=/usr/local/lib/pkgconfig/:/usr/lib/lib64/pkgconfig/ --prefix {home_location}/e2sar-install build --wipe && sed -i 's/-std=c++11//g' build/build.ninja\",\n",
    "    f\"cd E2SAR/build; PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/  meson compile -j 2\",\n",
    "]\n",
    "  \n",
    "execute_commands([sender, recver], commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50b9002-37cb-4c38-b280-95d09092a88b",
   "metadata": {},
   "source": [
    "## Running performance tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859bd430-87d7-48f9-871f-4c92dffd2dbc",
   "metadata": {},
   "source": [
    "We use `e2sar_perf` program located under bin/ to test performance of segmenting and reassembly code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c29be0-24b5-4250-8826-ed681f99081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# for e2sar_perf only the data= part of the query is meaningful. sync= must be present but is ignored\n",
    "# same for gRPC token, address and port (and lb id)\n",
    "e2sarPerfURI = f\"ejfat://useless@10.10.10.10:1234/lb/1?data={recver_addr}&sync=192.168.77.7:1234\"\n",
    "recverDuration = 20\n",
    "mtu = 0 # auto-detect\n",
    "rate = 25 # Gbps\n",
    "length = 1000000 # event length in bytes\n",
    "numEvents = 10000 # number of events to send\n",
    "bufSize = 300 * 1024 * 1024 # 100MB send and receive buffers\n",
    "\n",
    "# note that in back-to-back scenario you cannot have more than one receive thread as only one port can be received on\n",
    "recv_command = f\"cd E2SAR; PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/ ./build/bin/e2sar_perf -r -u '{e2sarPerfURI}' -d {recverDuration} -b {bufSize} --ip {recver_addr} --port 19522\"\n",
    "send_command = f\"cd E2SAR; PATH=$HOME/.local/bin:/usr/local/bin:$PATH LD_LIBRARY_PATH=/usr/local/lib/ ./build/bin/e2sar_perf -s -u '{e2sarPerfURI}' --mtu {mtu} --rate {rate} --length {length} -n {numEvents} -b {bufSize} --ip {sender_addr} -o liburing_send\"\n",
    "\n",
    "# start the receiver for 10 seconds and log its output\n",
    "print(f'Executing command {recv_command} on receiver')\n",
    "recver.execute_thread(recv_command, output_file=f\"{recver.get_name()}.perf.log\")\n",
    "\n",
    "# sleep 2 seconds to let receiver get going\n",
    "time.sleep(2)\n",
    "\n",
    "# start the sender in the foreground\n",
    "print(f'Executing command {send_command} on sender')\n",
    "stdout_send, stderr_send = sender.execute(send_command, output_file=f\"{sender.get_name()}.perf.log\")\n",
    "\n",
    "print(f\"Inspect {recver.get_name()}.perf.log file in your Jupyter container to see the results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a91bdf-ad59-45ab-b29c-1e1d3d4fa005",
   "metadata": {},
   "source": [
    "## Manage the slice\n",
    "\n",
    "### Extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c55dd8-6b83-4711-80e1-4d73d3de04d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set end to now plus 14 days\n",
    "end_date = (datetime.now(timezone.utc) + timedelta(days=14)).strftime(\"%Y-%m-%d %H:%M:%S %z\")\n",
    "\n",
    "try:\n",
    "    slice = fablib.get_slice(name=slice_name)\n",
    "\n",
    "    slice.renew(end_date)\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd1dbd-d502-461b-ad40-c589d7e32826",
   "metadata": {},
   "source": [
    "### Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f88bb58-a197-4853-9294-c90e2b250cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(slice_name)\n",
    "slice.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b909f-107f-4ff6-9fe1-baa14377fffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
